{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "##### By.\n",
    "##### A h M e D _ H e f N a w Y\n",
    "___________________\n",
    "#### Guide of Basic Linear Algebra for ML \n",
    "___________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !content\n",
    "_____________\n",
    "____________\n",
    "### SciPy is an ecosystem of Python libraries for mathematics, science and engineering. \n",
    "#### It is an add-on to Python that you will need for machine learning. The SciPy ecosystem is comprised of the following core module relevant to machine learning:\n",
    "##### - NumPy: A foundation for SciPy that allows you to efficiently work with data in arrays.\n",
    "___________\n",
    "_________\n",
    "###### ||||||||||||||||||||\n",
    "### - Arrays\n",
    "### - Matrices\n",
    "### - Factorization\n",
    "### - Statistics\n",
    "###### ||||||||||||||||||||\n",
    "______________________\n",
    "let's work! \n",
    "\n",
    "and make sure of versions and installations of required libararies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.3.1\n",
      "numpy: 1.16.5\n",
      "matplotlib: 3.1.1\n",
      "pandas: 0.25.1\n"
     ]
    }
   ],
   "source": [
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    " ## Array Manipulation \n",
    "- Create Array\n",
    "- Combining Arrays\n",
    "- Converting\n",
    "- Indexing\n",
    "- Slicing\n",
    "- Reshaping\n",
    "- Array Arithmetic\n",
    "- Broadcasting\n",
    "- Operations\n",
    "- Transpose\n",
    "- Dot Product\n",
    "- Aggregation\n",
    "- placeholders\n",
    "- Stacking\n",
    "- I/O\n",
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Array \n",
    "____________\n",
    "###### with diff types and diff ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "(3,)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# create normal array__________________\n",
    "l = [1.0, 2.0, 3.0]\n",
    "a = np.array(l)\n",
    "# display array\n",
    "print(a)\n",
    "# display array shape\n",
    "print(a.shape)\n",
    "# display array data type\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# create empty array ________________\n",
    "a = np.empty([3,5])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# create zero array\n",
    "a = np.zeros([4,5])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# create one array\n",
    "a = np.ones([4,5])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,10,2) # (start , stop , Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Combining Arrays\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Vertical Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______arr 1______\n",
      "[1 2 3]\n",
      "_______arr 2______\n",
      "[4 5 6]\n",
      "\n",
      "++++---- arr 1 >> vertical stack >> arr 2 ----++++\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "-------- SHAP >>>>\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# create array with vstack ###################\n",
    "# create first array\n",
    "a1 = np.array([1,2,3])\n",
    "print(\"_______arr 1______\")\n",
    "print(a1)\n",
    "# create second array\n",
    "a2 = np.array([4,5,6])\n",
    "print(\"_______arr 2______\")\n",
    "print(a2)\n",
    "# vertical stack\n",
    "a3 = np.vstack((a1, a2))\n",
    "print(\"\\n++++---- arr 1 >> vertical stack >> arr 2 ----++++\")\n",
    "print(a3)\n",
    "print(\"\\n-------- SHAP >>>>\")\n",
    "print(a3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Horizontal Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______arr 1______\n",
      "[1 2 3]\n",
      "_______arr 2______\n",
      "[4 5 6]\n",
      "______arr 1 >> HORIZONTAL stack >> arr 2_______\n",
      "[1 2 3 4 5 6]\n",
      "\n",
      "-------- SHAP >>>>\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "# create array with hstack\n",
    "# create first array\n",
    "a1 = np.array([1,2,3])\n",
    "print(\"_______arr 1______\")\n",
    "print(a1)\n",
    "# create second array\n",
    "a2 = np.array([4,5,6])\n",
    "print(\"_______arr 2______\")\n",
    "print(a2)\n",
    "# create horizontal stack\n",
    "a3 = np.hstack((a1, a2))\n",
    "print(\"______arr 1 >> HORIZONTAL stack >> arr 2_______\")\n",
    "print(a3)\n",
    "print(\"\\n-------- SHAP >>>>\")\n",
    "print(a3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting\n",
    "__________________\n",
    "##### - From List to Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### One-Dimensional List to Array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 22 33 44 55]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# create one-dimensional array\n",
    "# list of data\n",
    "data = [11, 22, 33, 44, 55]\n",
    "# array of data\n",
    "data = np.array(data)\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Two-Dimensional List of Lists to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 22]\n",
      " [33 44]\n",
      " [55 66]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# create two-dimensional array\n",
    "# list of data\n",
    "data = [[11, 22],\n",
    "[33, 44],\n",
    "[55, 66]]\n",
    "# array of data\n",
    "data = np.array(data)\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### index a one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "55\n",
      "55\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# define array\n",
    "data = np.array([11, 22, 33, 44, 55])\n",
    "# index data\n",
    "print(data[0])\n",
    "print(data[4])\n",
    "#print(data[5])# Access Error Wrong loocaion\n",
    "print(data[-1])\n",
    "print(data[-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two-Dimensional Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[11 22]\n"
     ]
    }
   ],
   "source": [
    "# index two-dimensional array\n",
    "\"\"\" \n",
    "    in c/c++  >> data[0,0]\n",
    "    in python >> data[0][0]\n",
    "\"\"\"\n",
    "# define array\n",
    "data = np.array([\n",
    "[11, 22],\n",
    "[33, 44],\n",
    "[55, 66]])\n",
    "# index data\n",
    "print(data[0,0])\n",
    "print(data[0,]) # [ROW , Coulmn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Slicing\n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Dimensional Slicing\n",
    "###### data[from:to]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\n",
      "[11 22]\n",
      "[11 22 33]\n",
      "[11 22 33 44]\n",
      "[11 22 33 44 55]\n",
      "[11 22 33 44 55]\n",
      "_____________________\n",
      "\n",
      "[55]\n",
      "[44 55]\n",
      "[33 44 55]\n",
      "[22 33 44 55]\n"
     ]
    }
   ],
   "source": [
    "# define array\n",
    "data = np.array([11, 22, 33, 44, 55])\n",
    "print(data[0:1])\n",
    "print(data[0:2])\n",
    "print(data[0:3])\n",
    "print(data[0:4])\n",
    "print(data[0:5])\n",
    "print(data[:])\n",
    "print(\"_____________________\\n\")\n",
    "#print(data[5:5])\n",
    "print(data[4:5])\n",
    "print(data[3:5])\n",
    "print(data[2:5])\n",
    "print(data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 55]\n"
     ]
    }
   ],
   "source": [
    "# negative slicing of a one-dimensional array\n",
    "print(data[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Dimensional Slicing\n",
    "- It is common to split your loaded data into input variables (X) and the output variable (y)\n",
    "\n",
    "##### X = [R : Rn ____ , ____C : Cn ]\n",
    "##### x = [ allROWS ( : ) , allColumns( : ) ]\n",
    "##### x = [ ___|___ , : ] >> All | Row\n",
    "##### x = [ : , __|__ ] >> All | Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ ALL DATA_____________\n",
      "\n",
      "[[11 22 33]\n",
      " [44 55 66]\n",
      " [77 88 99]]\n",
      "\n",
      "_______data[ : , : -1]_________\n",
      "\n",
      "[[11 22]\n",
      " [44 55]\n",
      " [77 88]]\n",
      "\n",
      "_______data[ : , -1]_________\n",
      "\n",
      "[33 66 99]\n",
      "=================\n",
      "\n",
      "s >>> \n",
      " [77 88 99]\n"
     ]
    }
   ],
   "source": [
    "# split input and output data\n",
    "# define array\n",
    "data = np.array([\n",
    "[11, 22, 33],\n",
    "[44, 55, 66],\n",
    "[77, 88, 99]])\n",
    "# separate data\n",
    "X, y = data[ : , : -1], data[ : , -1]\n",
    "print(\"_______ ALL DATA_____________\\n\")\n",
    "print(data)\n",
    "print(\"\\n_______data[ : , : -1]_________\\n\")\n",
    "print(X)\n",
    "print(\"\\n_______data[ : , -1]_________\\n\")\n",
    "print(y)\n",
    "print(\"=================\\n\")\n",
    "s = data[ -1 ,  : ]\n",
    "print(\"s >>> \\n\" , s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 22]\n",
      " [44 55]\n",
      " [77 88]]\n",
      "____________\n",
      "[33 66 99]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "[11, 22, 33],\n",
    "[44, 55, 66],\n",
    "[77, 88, 99]])\n",
    "# separate data\n",
    "X, y = data[ : , : -1 ] , data[ : , -1 ]\n",
    "print(X)\n",
    "print(\"____________\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#______________________________\n",
    "#### split dataset into separate\n",
    "- trainSet \n",
    "###### train = data[ : split ,  : ]\n",
    "- testSet    \n",
    "###### test =  data[ split : , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The REAL Data ---\n",
      " [[11 22 33]\n",
      " [44 55 66]\n",
      " [77 88 99]\n",
      " [10 10 10]] \n",
      "\n",
      "Split value =  2 \n",
      "\n",
      "TrainSet >> data[ : split , : ]: \n",
      " [[11 22 33]\n",
      " [44 55 66]]\n",
      "\n",
      "TestSet >> data [ split : , : ] : \n",
      " [[77 88 99]\n",
      " [10 10 10]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "[11, 22, 33],\n",
    "[44, 55, 66],\n",
    "[77, 88, 99],\n",
    "[10, 10, 10]])\n",
    "# print real data\n",
    "print(\"The REAL Data ---\\n\" , data , '\\n')\n",
    "# initializing split Value\n",
    "split = 2 \n",
    "print(\"Split value = \" , split , \"\\n\")\n",
    "# Splitting srtep - separate data -\n",
    "train,test = data[ : split , : ] , data [ split : , : ]\n",
    "# Printing \n",
    "print(\"TrainSet >> data[ : split , : ]: \\n\",train)\n",
    "print(\"\\nTestSet >> data [ split : , : ] : \\n\",test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "###### How to resize your data to meet the expectations of some machine learning APIs.\n",
    "______________\n",
    "#### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" one-dimensional array \"\"\"\n",
    "# define array\n",
    "data = array([1, 2, 3, 4, 5 , 6])\n",
    "# shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" two-dimensional array \"\"\"\n",
    "# list of data\n",
    "data = [[11, 22],\n",
    "[33, 44],\n",
    "[55, 66]]\n",
    "\n",
    "# array of data\n",
    "data = array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 3\n",
      "Number of Columnss: 2\n"
     ]
    }
   ],
   "source": [
    "# row and column shape of two-dimensional array\n",
    "# list of data\n",
    "data = [[11, 22],\n",
    "        [33, 44],\n",
    "        [55, 66]]\n",
    "\n",
    "#array of data\n",
    "data = array(data)\n",
    "\n",
    "print('Number of Rows: {}'.format( data.shape[0]) ) # zero for ROW\n",
    "print('Number of Columnss: {}'.format(data.shape[1])) # one for Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape 1D Array --> 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 8])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,10,2)#.reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10).reshape(2,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array \n",
      " [11 22 33 44 55] \n",
      "\n",
      "||||| original shap :----> (5,)\n",
      "=================== \n",
      " Reshaped Array \n",
      " [[11]\n",
      " [22]\n",
      " [33]\n",
      " [44]\n",
      " [55]] \n",
      "\n",
      "||||| Updated Shap :----> (5, 1)\n"
     ]
    }
   ],
   "source": [
    "# define array\n",
    "data = np.array([11, 22, 33, 44, 55])\n",
    "print( \"Original Array \\n\" , data ,'\\n')\n",
    "print(\"||||| original shap :---->\",data.shape)\n",
    "# reshape\n",
    "\"\"\" reshape ( Rows , Columns ) \"\"\"\n",
    "data = data.reshape(5, 1) \n",
    "print( \"=================== \\n Reshaped Array \\n\" , data ,'\\n')\n",
    "print(\"||||| Updated Shap :---->\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape 2D Array --> 3D Array\n",
    "###### data.reshape((data.shape[0], data.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data \n",
      " [[11 22 12  0]\n",
      " [33 44 34  0]\n",
      " [55 66 56  0]\n",
      " [33 44 34  0]]\n",
      "\n",
      " Data shap |--> (4, 4) \n",
      "______________________________\n",
      "Reshaped Array ||--->\n",
      " [[[11]\n",
      "  [22]\n",
      "  [12]\n",
      "  [ 0]]\n",
      "\n",
      " [[33]\n",
      "  [44]\n",
      "  [34]\n",
      "  [ 0]]\n",
      "\n",
      " [[55]\n",
      "  [66]\n",
      "  [56]\n",
      "  [ 0]]\n",
      "\n",
      " [[33]\n",
      "  [44]\n",
      "  [34]\n",
      "  [ 0]]]\n",
      "\n",
      " New Data shap |--> (4, 4, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#np.reshape()\n",
    "# list of data\n",
    "data = [[11, 22 , 12 ,0],\n",
    "[33, 44 , 34 ,0],\n",
    "[55, 66 , 56 ,0],\n",
    "[33, 44 , 34 ,0]]\n",
    "\n",
    "# array of data\n",
    "data = np.array(data)\n",
    "print(\"Original Data \\n\", data)\n",
    "print(\"\\n Data shap |-->\",data.shape,'\\n______________________________')\n",
    "\n",
    "# reshape\n",
    "data_R = data.reshape( 4 , 4 , 1)\n",
    "#++++++++++++++++++++\n",
    "print(\"Reshaped Array ||--->\\n\",data_R)\n",
    "print(\"\\n New Data shap |-->\", data_R.shape ,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Arithmetic\n",
    "_____________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! Limitation with Array Arithmetic\n",
    "- arithmetic may only be performed on arrays that have the same dimensions and dimensions with the same size .\n",
    "- This is a limitation on array arithmetic.\n",
    "##### Thankfully, NumPy provides a built-in workaround to allow arithmetic between arrays with differing sizes --->>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\## Array Broadcasting\n",
    "##### Broadcasting is the name given to the method that NumPy uses to allow array arithmetic between arrays with a different shape or size.\n",
    "###### by in effect replicating the smaller array along the last mismatched dimension ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "........\n",
    "\n",
    "Broadcasting in NumPy\n",
    "- We can make broadcasting concrete by looking at three examples in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Scalar and One-Dimensional Array\n",
    "##### scalar can be used in arithmetic with a one-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array \n",
      " [1 2 3] \n",
      "\n",
      "----------\n",
      "Scalar Value =  2 \n",
      "broadcast -> c = a + b \n",
      "------------\n",
      "\n",
      "After Broadcasting\n",
      " [3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# broadcast scalar to one-dimensional array\n",
    "# define array\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "# define scalar\n",
    "b_Scalar = 2\n",
    "\n",
    "# broadcast\n",
    "c = a + b_Scalar\n",
    "\n",
    "print(\"Original Array \\n\", a ,'\\n' )\n",
    "print(\"----------\\nScalar Value = \",b_Scalar,'\\nbroadcast -> c = a + b \\n------------')\n",
    "print(\"\\nAfter Broadcasting\\n\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   2) Scalar and Two-Dimensional Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array \n",
      " [[1 2 3]\n",
      " [1 2 3]] \n",
      "\n",
      "----------\n",
      "Scalar Value =  2 \n",
      "broadcast -> C = A + b \n",
      "------------\n",
      "\n",
      "After Broadcasting\n",
      " [[3 4 5]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# broadcast scalar to two-dimensional array\n",
    "\n",
    "# define array\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[1, 2, 3]])\n",
    "\n",
    "# define scalar\n",
    "b_Scalar = 2\n",
    "\n",
    "# broadcast\n",
    "C = A + b_Scalar\n",
    "\n",
    "print(\"Original Array \\n\", A ,'\\n' )\n",
    "print(\"----------\\nScalar Value = \",b_Scalar,'\\nbroadcast -> C = A + b \\n------------')\n",
    "print(\"\\nAfter Broadcasting\\n\",C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) One-Dimensional and Two-Dimensional Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array \n",
      " [[1 2 3]\n",
      " [1 2 3]] \n",
      "\n",
      "----------\n",
      "Scalar Value =  [1 2 3] \n",
      "broadcast -> C = A + b \n",
      "------------\n",
      "\n",
      "After Broadcasting\n",
      " [[2 4 6]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "# broadcast one-dimensional array to two-dimensional array\n",
    "# define two-dimensional array\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[1, 2, 3]])\n",
    "\n",
    "# define one-dimensional array\n",
    "b_Scalar = array([1,2,3])\n",
    "\n",
    "# broadcast\n",
    "C = A + b_Scalar\n",
    "\n",
    "print(\"Original Array \\n\", A ,'\\n' )\n",
    "print(\"----------\\nScalar Value = \",b_Scalar,'\\nbroadcast -> C = A + b \\n------------')\n",
    "print(\"\\nAfter Broadcasting\\n\",C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! Limitations of Broadcasting\n",
    "##### Arithmetic, including broadcasting, can only be performed when the shape of each dimension in the arrays are equal or one has the dimension size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shap of Array : (2, 3) \n",
      "\n",
      "The shap of Scalar : (2,) \n",
      "\n",
      "!!ERROR broadcast >>\n",
      " ValueError: operands could not be broadcast together with shapes (2,3) (2,) \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7b3555f151c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# !!ERROR broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_Scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original Array \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------\\nScalar Value = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_Scalar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\nbroadcast -> C = A + b \\n------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,) "
     ]
    }
   ],
   "source": [
    "# broadcast one-dimensional array to two-dimensional array\n",
    "# define two-dimensional array\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[1, 2, 3]])\n",
    "\n",
    "# define one-dimensional array\n",
    "b_Scalar = np.array([1,2])\n",
    "\n",
    "print('The shap of Array :' , A.shape ,'\\n')\n",
    "print('The shap of Scalar :' , b_Scalar.shape ,'\\n')\n",
    "print('!!ERROR broadcast >>\\n','ValueError: operands could not be broadcast together with shapes (2,3) (2,) \\n \\n')\n",
    "\n",
    "# !!ERROR broadcast\n",
    "C = A + b_Scalar\n",
    "print(\"Original Array \\n\", A ,'\\n' )\n",
    "print(\"----------\\nScalar Value = \",b_Scalar,'\\nbroadcast -> C = A + b \\n------------')\n",
    "#print(\"\\nAfter Broadcasting\\n\",C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices\n",
    "- Vectors and Vector Arithmetic\n",
    "- Vector Norms\n",
    "- Matrices and Matrix Arithmetic\n",
    "- Types of Matrices\n",
    "- Matrix Operations\n",
    "- Sparse Matrices\n",
    "- Tensors and Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector is a tuple of one or more values called scalars.\n",
    "###### We can represent a vector in Python as a NumPy array.\n",
    "#### Vectors and Vector Arithmetic\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector V = [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# >>>>>>>>>>>>>>>>>> create a vector\n",
    "# define vector\n",
    "v = np.array([1, 2, 3])\n",
    "print('Vector V =',v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector Addition\n",
    "###### c = a + b\n",
    "###### c = (a1 + b1; a2 + b2; a3 + b3)\n",
    "###### =================\n",
    "###### c[0] = a[0] + b[0]\n",
    "###### c[1] = a[1] + b[1]\n",
    "###### c[2] = a[2] + b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-Vector [1 2 3]\n",
      "Second-Vector [1 2 3]\n",
      "Operation : c = a + b\n",
      "\n",
      "Result Vector [2 4 6]\n"
     ]
    }
   ],
   "source": [
    "# >>>>>>>>>>>>>>>>> vector addition\n",
    "# define first vector\n",
    "a = np.array([1, 2, 3])# V1\n",
    "print(\"First-Vector\",a)\n",
    "# define second vector \n",
    "b = np.array([1, 2, 3]) # V2\n",
    "print(\"Second-Vector\",b)\n",
    "# add vectors\n",
    "c = a + b\n",
    "print('Operation : c = a + b')\n",
    "print(\"\\nResult Vector\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-Vector : [1 2 3]\n",
      "Second-Vector [0.5 0.5 0.5]\n",
      "Operation : c = a - b\n",
      "\n",
      "Result-Vector : [0.5 1.5 2.5]\n"
     ]
    }
   ],
   "source": [
    "# vector subtraction\n",
    "# define first vector\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "print('First-Vector :',a)\n",
    "# define second vector\n",
    "b = np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "print('Second-Vector',b)\n",
    "# subtract vectors\n",
    "c = a - b\n",
    "print('Operation : c = a - b')\n",
    "print('\\nResult-Vector :',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector Multiplication\n",
    "###### c = a × b\n",
    "###### c = (a1 × b1; a2 × b2; a3 × b3)\n",
    "###### c = (a1b1; a2b2; a3b3)\n",
    "###### =================================\n",
    "###### c[0] = a[0] × b[0]\n",
    "###### c[1] = a[1] × b[1]\n",
    "###### c[2] = a[2] × b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-Array [1 2 3]\n",
      "Second-Array [1 2 3]\n",
      "Operation : c = a * b\n",
      "\n",
      "Result-Array [1 4 9]\n"
     ]
    }
   ],
   "source": [
    "# vector multiplication\n",
    "from numpy import array\n",
    "# define first vector\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "# define second vector\n",
    "b = np.array([1, 2, 3])\n",
    "# multiply vectors\n",
    "c = a * b\n",
    "print('First-Array',a)\n",
    "print('Second-Array',b)\n",
    "print('Operation : c = a * b')\n",
    "print('\\nResult-Array',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector Division\n",
    "###### C = A/B \n",
    "###### =================\n",
    "##### c[0] = a[0] / b[0]\n",
    "##### c[1] = a[1] / b[1]\n",
    "##### c[2] = a[2] / b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-Array [1 2 3]\n",
      "Second-Array [1 2 3]\n",
      "Operation : C = a/b\n",
      "\n",
      "Result-Array [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# vector division\n",
    "# define first vector\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "# define second vector\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "# divide vectors\n",
    "c = a / b\n",
    "\n",
    "print('First-Array',a)\n",
    "print('Second-Array',b)\n",
    "print('Operation : C = a/b')\n",
    "print('\\nResult-Array',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Dot Product\n",
    "calculate the sum of the multiplied elements of two vectors of the same length to give a\n",
    "scalar.\n",
    "##### c = a · b\n",
    "used in machine learning to calculate the weighted sum of a vector.\n",
    "\n",
    "The dot product is calculated as follows: \n",
    "- c = (a1b1 + a2b2 + a3b3)\n",
    "###### We can represent a Dot Product in Python as a dot() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-Vector : [1 2 3]\n",
      "Second-Vector : [1 2 3]\n",
      "______________\n",
      "multiply Operation [1 4 9]\n",
      "Result Dot Product : 14\n"
     ]
    }
   ],
   "source": [
    "# vector dot product\n",
    "# define first vector\n",
    "a = np.array([1, 2, 3])\n",
    "# define second vector\n",
    "b = np.array([1, 2, 3])\n",
    "# multiply vectors\n",
    "c = a.dot(b)\n",
    "print('First-Vector :',a)\n",
    "print('Second-Vector :',b)\n",
    "print('______________\\nmultiply Operation' , a*b)\n",
    "print('Result Dot Product :',c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector-Scalar Multiplication\n",
    "A vector can be multiplied by a scalar, in effect scaling the magnitude of the vector. To keep\n",
    "notation simple, we will use lowercase S to represent the scalar value.\n",
    "##### C = S × V\n",
    "##### C = SV\n",
    "The multiplication is performed on each element of the vector to result in a new scaled\n",
    "vector of the same length.\n",
    "##### C = (S × v1; S × v2; S × v3)\n",
    "###### c[0] = v[0] × s\n",
    "###### c[1] = v[1] × s\n",
    "###### c[2] = v[2] × s\n",
    "\n",
    "\n",
    "!! Similarly, vector-scalar addition, subtraction, and division can be performed in the same\n",
    "way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoer : [1 2 3]\n",
      "Scalar : 0.5\n",
      "\n",
      "Result Dot Product with b Vector : 14\n",
      "\n",
      "Vector-Scalar Multiplication [0.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "#>>>>>>>> vector-scalar multiplication\n",
    "# define vector\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 2, 3])\n",
    "\n",
    "# define scalar\n",
    "scala_R = 0.5\n",
    "\n",
    "# multiplication\n",
    "c = scala_R * a\n",
    "\n",
    "print('Vectoer :',a)\n",
    "print('Scalar :',scala_R)\n",
    "print('\\nResult Dot Product with b Vector :',a.dot(b))\n",
    "print('\\nVector-Scalar Multiplication',c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "### Vector Norms\n",
    "##### The length of a vector is a nonnegative number that describes the extent of the vector in space,length, ----> and is sometimes referred to as the vector’s magnitude or the norm\n",
    "\n",
    "##### Notations are used to represent the vector norm in broader calculations and the type\n",
    "##### of vector norm calculation almost always has its own unique notation.\n",
    "________________\n",
    "\n",
    "##### vector norm calculations used in machine learning. >>\n",
    "==========================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------------ 1) !! Vector L^1 Norm\n",
    "called the taxicab norm or the Manhattan norm.\n",
    "\n",
    "The notation for the L^1 norm of a vector is ||v||^1 -- where 1 is a subscript .\n",
    "\n",
    "### L^1(v) = ||v||1\n",
    "#### ||V||^1 = |a1| + |a2| + |a3|\n",
    "##### The L^1 norm is calculated as the sum of the absolute vector values, where the absolute value of a scalar uses the notation |a1| . In effect, the norm is a calculation of the Manhattan distance from the origin of the vector space.\n",
    "\n",
    "The L^1 norm is often used when fitting machine learning algorithms as a regularization\n",
    "method, e.g. a method to keep the coefficients of the model small, and in turn, the model less\n",
    "complex\n",
    "\n",
    "**\n",
    "###### >>>> The L^1 norm of a vector can be calculated in NumPy using the norm() function with a parameter to specify the norm order, in this case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector > [1 2 3]\n",
      "L1 Norm>  6.0\n"
     ]
    }
   ],
   "source": [
    "# vector L1 norm\n",
    "# define vector\n",
    "from numpy.linalg import norm\n",
    "a = np.array([1, 2, 3])\n",
    "print(\"Vector >\",a)\n",
    "\n",
    "# calculate norm\n",
    "l1 = norm(a, 1)\n",
    "\n",
    "print('L1 Norm> ',l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ++++++++++++++++++++++++++++\n",
    "#### ------------------------------------------------   2) !! Vector L^2 Norm\n",
    "known as the Euclidean norm as it is calculated as the Euclidean distance from the origin.\n",
    "\n",
    "The L2 norm calculates the distance of the vector coordinate from the origin of the vector space.\n",
    "\n",
    "### L^2(v) = ||v||2\n",
    "#### ||V||2 = Sqrt[ (a1)^2 + (a2)^2 + (a3)^2 ]\n",
    "##### The L^2 norm is calculated as the square root of the sum of the squared vector values\n",
    "\n",
    "Like the L^1 norm, the L^2 norm is often used when fitting machine learning algorithms as a\n",
    "regularization method, e.g. a method to keep the coefficients of the model small and, in turn,\n",
    "the model less complex. By far, the L2 norm is more commonly used than other vector norms\n",
    "in machine learning\n",
    "\n",
    "###### >>>> The L^2 norm of a vector can be calculated in NumPy using the norm() function with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector >> [1 2 3]\n",
      "L2 norm 3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "# vector L2 norm\n",
    "# define vector\n",
    "from numpy.linalg import norm\n",
    "a = np.array([1, 2, 3])\n",
    "print('Vector >>',a)\n",
    "\n",
    "# calculate norm\n",
    "l2 = norm(a)\n",
    "print('L2 norm',l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ++++++++++++++++++++++++++++\n",
    "#### ------------------------------------------------   3) !! Vector Max(n) Norm   \n",
    "also called max norm. \n",
    "\n",
    "Max norm of a vector is referred to as Linf where inf is a superscript and can be represented with the infinity symbol. The notation for max norm is jjvjjinf, where inf is a subscript.\n",
    "\n",
    "### L^inf(V) = ||v||inf\n",
    "#### ||V||^inf = max a1,a2,a3\n",
    "##### The max norm is calculated as returning the maximum value of the vector, hence the name.\n",
    "\n",
    "Max norm is also used as a regularization in machine learning, such as on neural network\n",
    "weights, called max norm regularization.\n",
    "\n",
    "###### >>>> The max norm of a vector can be calculated in NumPy using the norm() function with the order MATH parameter set to --> inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-228ae88435eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# define vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Vector >>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# calculate norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# vector max norm\n",
    "from math import inf\n",
    "# define vector\n",
    "a = np.array([1, 2, 3 , 5, 1, 7,  12, 2])\n",
    "print('Vector >>',a)\n",
    "# calculate norm\n",
    "maxnorm = np.norm(a, inf)\n",
    "print('Max_Norm >>',maxnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices and Matrix Arithmetic\n",
    "________________\n",
    "A matrix is a two-dimensional array of scalars with one or more columns and one or more rows.\n",
    "\n",
    "A matrix is a two-dimensional array (a table) of numbers.\n",
    "#### A = [(a1,1; a1,2); (a2,1; a2,2); (a3,1; a3,2)]\n",
    "\n",
    "- The geometric analogy used to help understand vectors and some of their operations does not\n",
    "hold with matrices. Further, a vector itself may be considered a matrix with one column and\n",
    "multiple rows.\n",
    "- Often the dimensions of the matrix are denoted as m and n or m × n for the\n",
    "number of rows and the number of columns respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ++++++++++++++++++++++++++\n",
    "### Defining a Matrix\n",
    "##### We can represent a matrix in Python using a two-dimensional NumPy array. A NumPy array can be constructed given a list of lists. \n",
    "###### For example, below is a 2 row, 3 column matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Matrix >>\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# create matrix\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print('Created Matrix >>\\n',A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ++++++++++++++++++++++++++\n",
    "### Matrix Arithmetic\n",
    "##### where all operations are performed element-wise between two matrices of equal size to result in a new matrix with the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 1) Matrix Addition\n",
    "###### C = A + B\n",
    "The scalar elements in the resulting matrix are calculated as the addition of the elements in\n",
    "each of the matrices being added\n",
    "###### The example first defines two 2 × 3 matrices and then adds them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Matrix B :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Operation : C = A + B \n",
      "\n",
      "_____________\n",
      "Result-Matrix \n",
      " [[ 2  4  6]\n",
      " [ 8 10 12]]\n"
     ]
    }
   ],
   "source": [
    "# matrix addition\n",
    "# define first matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "# define second matrix\n",
    "B = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# add matrices\n",
    "C = A + B\n",
    "print('Matrix A :\\n', A )\n",
    "print('\\nMatrix B :\\n',B )\n",
    "print('\\nOperation : C = A + B \\n' )\n",
    "print('_____________\\nResult-Matrix \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 2) Matrix Subtraction\n",
    "###### C = A - B\n",
    "The scalar elements in the resulting matrix are calculated as the subtraction of the elements\n",
    "in each of the matrices.\n",
    "###### The example first defines two 2 ×3 matrices and then subtracts one from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Matrix B :\n",
      " [[0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5]]\n",
      "\n",
      "Operation : C = A - B \n",
      "\n",
      "_____________\n",
      "Result-Matrix \n",
      " [[0.5 1.5 2.5]\n",
      " [3.5 4.5 5.5]]\n"
     ]
    }
   ],
   "source": [
    "# matrix subtraction\n",
    "# define first matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# define second matrix\n",
    "B = np.array([\n",
    "[0.5, 0.5, 0.5],\n",
    "[0.5, 0.5, 0.5]])\n",
    "\n",
    "# subtract matrices\n",
    "C = A - B\n",
    "print('Matrix A :\\n', A )\n",
    "print('\\nMatrix B :\\n',B )\n",
    "print('\\nOperation : C = A - B \\n' )\n",
    "print('_____________\\nResult-Matrix \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "#### ------------------------------------------- 3) Matrix Division\n",
    "###### C = A/B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Matrix B :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Operation : C = A/B \n",
      "\n",
      "_____________\n",
      "Result-Matrix \n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# matrix division\n",
    "# define first matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# define second matrix\n",
    "B = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# divide matrices\n",
    "C = A / B\n",
    "\n",
    "print('Matrix A :\\n', A )\n",
    "print('\\nMatrix B :\\n',B )\n",
    "print('\\nOperation : C = A/B \\n' )\n",
    "print('_____________\\nResult-Matrix \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 4) Matrix Multiplication (Hadamard Product - element-wise matrix multiplication)\n",
    "###### C = A ◦ B\n",
    "Two matrices with the same size can be multiplied together, and this is often called element-wise\n",
    "matrix multiplication or the Hadamard product. \n",
    "###### It is not the typical operation meant when referring to matrix multiplication, therefore a different operator is often used, such as a circle ◦ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Matrix B :\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Operation : C = A * B \n",
      "\n",
      "_____________\n",
      "Result-Matrix \n",
      " [[ 1  4  9]\n",
      " [16 25 36]]\n"
     ]
    }
   ],
   "source": [
    "# matrix Hadamard product\n",
    "from numpy import array\n",
    "# define first matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# define second matrix\n",
    "B = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6]])\n",
    "\n",
    "# multiply matrices\n",
    "C = A * B\n",
    "\n",
    "\n",
    "print('Matrix A :\\n', A )\n",
    "print('\\nMatrix B :\\n',B )\n",
    "print('\\nOperation : C = A * B \\n' )\n",
    "print('_____________\\nResult-Matrix \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 5) Matrix Multiplication (dot product)\n",
    "###### C = A · B  or  C = AB\n",
    "##### Matrix multiplication, also called the matrix dot product is more complicated than the previous operations and involves a rule as not all matrices can be multiplied together.\n",
    "\n",
    "##### It is not the typical operation meant when referring to matrix multiplication, therefore a different operator is often used, such as a circle ◦ \n",
    "##### It is not the typical operation of VECTOR DOT PRODUCT that, calculate the sum of multiplied elemnts \n",
    "\n",
    ": : : : : : : : : The rule for matrix multiplication is as follows:\n",
    "- The number of columns (n) in the first matrix (A) must equal the number of rows (m) in\n",
    "the second matrix (B) .\n",
    "-  >  C [m,k] = A[ m,n ] · B[ n,k ]\n",
    "###### The matrix multiplication operation can be implemented in NumPy using the dot() function. It can also be calculated using the newer @ operator, since Python version 3.5. The example below demonstrates both methods - Example of matrix-matrix dot product -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A :\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Matrix B :\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "\n",
      "-----Result of -multiply matrices :\n",
      " [[ 7 10]\n",
      " [15 22]\n",
      " [23 34]]\n",
      "\n",
      "-----Result of -multiply matrices with @ operator :\n",
      " [[ 7 10]\n",
      " [15 22]\n",
      " [23 34]]\n"
     ]
    }
   ],
   "source": [
    "# matrix dot product\n",
    "# define first matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('Matrix A :\\n',A)\n",
    "# define second matrix\n",
    "B = np.array([\n",
    "[1, 2],\n",
    "[3, 4]])\n",
    "print('Matrix B :\\n',B)\n",
    "# multiply matrices\n",
    "C = A.dot(B)\n",
    "print('\\n-----Result of -multiply matrices :\\n',C)\n",
    "# multiply matrices with @ operator\n",
    "D = A @ B\n",
    "print('\\n-----Result of -multiply matrices with @ operator :\\n',D)\n",
    "\n",
    "#I recommend using the dot() function for matrix multiplication for now given the newness of the @ operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 6) Matrix-Vector Multiplication\n",
    "###### c = A · v or c = Av\n",
    "\n",
    "A matrix and a vector can be multiplied together as long as the rule of matrix multiplication\n",
    "is observed. Specifically, that the number of columns in the matrix must equal the number of\n",
    "items in the vector. As with matrix multiplication, the operation can be written using the dot\n",
    "notation. Because the vector only has one column, the result is always a vector \n",
    "##### The result is a vector with the same number of rows as the parent matrix .\n",
    "###### The matrix-vector multiplication can be implemented in NumPy using the dot() function .\n",
    "The example first defines a (3 × 2) matrix and a (2 * 1) element vector and then multiplies them\n",
    "together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix :\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Vector v :\n",
      " [0.5 0.5]\n",
      "\n",
      " The result - VECTOR :\n",
      " [1.5 3.5 5.5]\n"
     ]
    }
   ],
   "source": [
    "# matrix-vector multiplication\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('Matrix :\\n',A)\n",
    "# define vector\n",
    "B = np.array([0.5, 0.5])\n",
    "print('Vector v :\\n',B)\n",
    "# multiply\n",
    "C = A.dot(B)\n",
    "print('\\n The result - VECTOR :\\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ------------------------------------------- 7) Matrix-Scalar Multiplication\n",
    "###### C = A · b  |or|  C = Ab\n",
    "A matrix can be multiplied by a scalar. This can be represented using the dot notation between\n",
    "the matrix and the scalar.\n",
    "###### C[0,0] = A[0,0] × b\n",
    "###### C[1,0] = A[1,0] × b\n",
    "###### C[2,0] = A[2,0] × b\n",
    "###### C[0,1] = A[0,1] × b\n",
    "###### C[1,1] = A[1,1] × b\n",
    "###### C[2,1] = A[2,1] × b\n",
    "\n",
    "##### The result is a matrix with the same size as the parent matrix where each element of the matrix is multiplied by the scalar value.\n",
    "\n",
    "###### This can be implemented directly in NumPy with the multiplication operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A : \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "SCALAR b = 0.5\n",
      "________________\n",
      "Rsult - MATRIX : \n",
      " [[0.5 1. ]\n",
      " [1.5 2. ]\n",
      " [2.5 3. ]]\n"
     ]
    }
   ],
   "source": [
    "# matrix-scalar multiplication\n",
    "\n",
    "# define matrix\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "print('Matrix A : \\n',A)\n",
    "# define scalar\n",
    "b = 0.5\n",
    "print('\\nSCALAR b =',b)\n",
    "# multiply\n",
    "C = A * b\n",
    "print('________________\\nRsult - MATRIX : \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "#### Types of Matrices\n",
    "\n",
    "the main diagonal : The vector of values along the diagonal of the matrix from the top left to the\n",
    "bottom right.\n",
    "________________\n",
    "##### Square Matrix ( M )\n",
    "A square matrix is a matrix where the number of rows (n) is equivalent to the number of\n",
    "columns (m).\n",
    "n ≡ m\n",
    "###### M = >>>>>>>>> 3 square matrix\n",
    "######     [ 1 2 3 ]\n",
    "######     [ 1 2 3 ]\n",
    "######     [ 1 2 3 ]\n",
    "\n",
    "Square matrices are readily added and multiplied together and are the basis of many simple\n",
    "linear transformations, such as rotations (as in the rotations of images).\n",
    "\n",
    "- Symmetric Matrix ( S )\n",
    "##### A symmetric matrix is a type of square matrix where the top-right triangle is the same as the bottom-left triangle\n",
    "###### S = >>>>>>>>>>>>> 5 × 5 symmetric matrix.\n",
    "####     [ 1 2 3 4 5 ]\n",
    "####     [ 2 1 2 3 4 ]\n",
    "####     [ 3 2 1 2 3 ]\n",
    "####     [ 4 3 2 1 2 ]\n",
    "####     [ 5 4 3 2 1 ]\n",
    "!! It is no exaggeration to say that symmetric matrices S are the most important matrices the world will ever see | in the theory of linear algebra and also in the applications.\n",
    "-------------------------------------\n",
    "- Triangular Matrix ( M )\n",
    "##### A triangular matrix is a type of square matrix that has all values in the upper-right or lower-left of the matrix with the remaining elements filled with zero values.\n",
    "-\n",
    "###### M = >>>>>>>>>>>>> 3 × 3 upper triangular matrix.\n",
    "####     [ 1 2 3 ]\n",
    "####     [ 0 1 2 ]\n",
    "####     [ 0 0 1 ]\n",
    "-\n",
    "###### M = >>>>>>>>>>>>> 3 × 3 lower triangular matrix.\n",
    "####     [ 1 0 0 ]\n",
    "####     [ 5 1 0 ]\n",
    "####     [ 1 2 1 ]\n",
    "###### NumPy provides functions to calculate a triangular matrix from an existing square matrix. The tril() function to calculate the lower triangular matrix from a given matrix and the triu() to calculate the upper triangular matrix from a given matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square Matrix :\n",
      " [[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n",
      "\n",
      "lower triangular matrix : \n",
      " [[1 0 0]\n",
      " [1 2 0]\n",
      " [1 2 3]]\n",
      "upper triangular matrix : \n",
      " [[1 2 3]\n",
      " [0 2 3]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# triangular matrices\n",
    "# define square matrix\n",
    "M = np.array([\n",
    "[1, 2, 3],\n",
    "[1, 2, 3],\n",
    "[1, 2, 3]])\n",
    "print('Square Matrix :\\n',M)\n",
    "\n",
    "# lower triangular matrix\n",
    "lower = np.tril(M)\n",
    "print('\\nlower triangular matrix : \\n',lower)\n",
    "\n",
    "# upper triangular matrix\n",
    "upper = np.triu(M)\n",
    "print('upper triangular matrix : \\n',upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diagonal Matrix ( D )\n",
    "\n",
    "###### A diagonal matrix is one where values outside of the main diagonal have a zero value, where the main diagonal is taken from the top left of the matrix to the bottom right.\n",
    "###### A diagonal matrix is often denoted with the variable D and may be represented as a full matrix or as a vector of values on the main diagonal.\n",
    " \n",
    "Diagonal matrices consist mostly of zeros and have non-zero entries only along the\n",
    "main diagonal.\n",
    "\n",
    "###### D = >>>>>>>>>>>>> 3 × 3 square diagonal matrix.\n",
    "####     [ 1 0 0 ]\n",
    "####     [ 0 2 0 ]\n",
    "####     [ 0 0 3 ]\n",
    "\n",
    "##### d = >>>>>>>>>>>>> as a VECTOR.\n",
    "####     [ d(1,1) ]\n",
    "####     [ d(2,2) ]\n",
    "####     [ d(3,3) ]\n",
    "\n",
    "##### d = >>>>>>>>>>>>> with the specified scalar values.\n",
    "####     [ 1 ]\n",
    "####     [ 2 ]\n",
    "####     [ 3 ]\n",
    "##### d = >>>>>>>>>>> As a Non-Square\n",
    "#### [1 0 0 0]\n",
    "#### [0 2 0 0]\n",
    "#### [0 0 3 0]\n",
    "#### [0 0 0 4]\n",
    "#### [0 0 0 0]\n",
    "\n",
    "###### this examble axplain how to extracts the main diagonal as a vector, and then creates a diagonal matrix from the extracted vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square matrix : \n",
      " [[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n",
      "\n",
      "________________________|  extract diagonal vector : \n",
      " [1 2 3]\n",
      "\n",
      "________________________|  create diagonal matrix from vector : \n",
      " [[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# diagonal matrix\n",
    "\n",
    "# define square matrix\n",
    "M = np.array([\n",
    "[1, 2, 3],\n",
    "[1, 2, 3],\n",
    "[1, 2, 3]])\n",
    "print('square matrix : \\n',M)\n",
    "# extract diagonal vector\n",
    "d = np.diag(M)\n",
    "print('\\n________________________|  extract diagonal vector : \\n',d)\n",
    "# create diagonal matrix from vector\n",
    "D = np.diag(d)\n",
    "print('\\n________________________|  create diagonal matrix from vector : \\n',D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Matrix ( I ) or ( U )\n",
    "is a square matrix that does not change a vector when multiplied. The\n",
    "values of an identity matrix are known. All of the scalar values along the main diagonal (top-left\n",
    "to bottom-right) have the value one, while all other values are zero.\n",
    "#### this is different from a Unitary matrix)\n",
    "**\n",
    "##### An identity matrix is a matrix that does not change any vector when we multiply that vector by that matrix.\n",
    "###### I or U = >>>>>>>>>>>>> Identity Matrix or unit matrix.\n",
    "####     [ 1 0 0 ]\n",
    "####     [ 0 1 0 ]\n",
    "####     [ 0 0 1 ]\n",
    "\n",
    "###### In NumPy, an identity matrix can be created with a specific size using the identity() function. The example below creates an I3 identity matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity Matrix : \n",
      "-------------- \n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# identity matrix\n",
    "I = np.identity(3)\n",
    "print('Identity Matrix : \\n-------------- \\n',I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orthogonal Matrix ( Q )\n",
    "orthogonal matrix is a type of square matrix whose columns and rows are orthonormal\n",
    "unit vectors, e.g. perpendicular and have a length or magnitude of 1.\n",
    "\n",
    "A matrix is orthogonal if its transpose is equal to its inverse  -->> Q^T = Q^ −1\n",
    "\n",
    "orthogonal matrix is if the dot product of the matrix and itself equals the identity matrix ---> Q · Q^T = I\n",
    "\n",
    "The Orthogonal matrix is defined formally as follows:\n",
    "\n",
    "QT · Q = Q · Q^T = I\n",
    "##### v · w = 0\n",
    "##### v · w^T = 0\n",
    "\n",
    "Orthogonal matrices are used a lot for linear transformations, such as reflections and\n",
    "permutations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orthogonal matrix : \n",
      " [[ 1  0]\n",
      " [ 0 -1]]\n",
      "inverse of the orthogonal matrix : \n",
      " [[ 1  0]\n",
      " [ 0 -1]]\n",
      "transpose of the orthogonal matrix : \n",
      " [[ 1.  0.]\n",
      " [-0. -1.]]\n",
      "\n",
      "-----------------------------------------\n",
      "identity matrix is printed which is calculated from the dot product of the orthogonal matrix with its transpose : \n",
      " [[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# orthogonal matrix\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# define orthogonal matrix\n",
    "Q = np.array([\n",
    "[1, 0],\n",
    "[0, -1]])\n",
    "print('orthogonal matrix : \\n',Q)\n",
    "# inverse equivalence\n",
    "V = inv(Q)\n",
    "\n",
    "print('inverse of the orthogonal matrix : \\n',Q.T)\n",
    "print('transpose of the orthogonal matrix : \\n',V)\n",
    "# identity equivalence\n",
    "I = Q.dot(Q.T)\n",
    "print('\\n-----------------------------------------\\nidentity matrix is printed which is calculated from the dot product of the orthogonal matrix with its transpose : \\n',I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "____________________________________________\n",
    "## Matrix Operations\n",
    "__________________________________________\n",
    "Matrix operations are used in the description of many machine learning algorithms.\n",
    "\n",
    "Some operations can be used directly to solve key equations,\n",
    "\n",
    "whereas others provide useful shorthand or foundation in the description and the use of more complex matrix operations\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose (A^T)\n",
    "#### which creates a new matrix with the number of columns and rows flipped. This is denoted by the superscript T next to the matrix A^T.\n",
    "###### C = A^T\n",
    "The operation has no effect if the matrix is symmetrical, e.g. has the same number of\n",
    "columns and rows and the same values at the same locations on both sides of the invisible\n",
    "diagonal line.\n",
    "\n",
    "#### A = >>>>>>>>>>> \n",
    "#### [1 2]         \n",
    "#### [3 4]       \n",
    "#### [5 6] \n",
    "**\n",
    "#### A^T = >>>>\n",
    "#### [ 1 3 5 ]\n",
    "#### [ 2 4 6 ]\n",
    "\n",
    "###### We can transpose a matrix in NumPy by calling the T attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "A transpose : \n",
      " [[1 3 5]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "# transpose matrix\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('Matrix A: \\n',A)\n",
    "# calculate transpose\n",
    "C = A.T\n",
    "print('A transpose : \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse ( A^ -1 )\n",
    "finds another matrix that when multiplied with the matrix, results in an identity matrix .\n",
    "#### AB = BA = I^n\n",
    "B is the inverse of A.\n",
    "#### B = A^−1\n",
    "\n",
    "\n",
    "Matrix inversion is used as an operation in solving systems of\n",
    "equations framed as matrix equations where we are interested in finding vectors of unknowns.\n",
    "A good example is in finding the vector of coefficient values in linear regression.\n",
    "\n",
    "###### A matrix can be inverted in NumPy using the inv() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A: \n",
      " [[1. 2.]\n",
      " [3. 4.]]\n",
      "_____________________\n",
      " invert matrix A ^-1 : \n",
      " [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "______________________ \n",
      "\n",
      " Identity matrix that calc by multiply A.dot(B) : \n",
      " \n",
      " [[1.00000000e+00 1.11022302e-16]\n",
      " [0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# invert matrix\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1.0, 2.0],\n",
    "[3.0, 4.0]])\n",
    "print('Matrix A: \\n',A)\n",
    "\n",
    "# invert matrix\n",
    "B = inv(A)\n",
    "print('_____________________\\n invert matrix A ^-1 : \\n',B)\n",
    "# multiply A and B\n",
    "I = A.dot(B)\n",
    "print('______________________ \\n\\n Identity matrix that calc by multiply A.dot(B) : \\n \\n',I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\n",
    "*\n",
    "### TRACE \n",
    "The trace operator gives the sum of all of the diagonal entries of a matrix\n",
    "\n",
    "The operation of calculating a trace on a square matrix is described using the notation tr(A)\n",
    "where A is the square matrix on which the operation is being performed.\n",
    "##### tr(A) (11.6)\n",
    "The trace is calculated as the sum of the diagonal values; for example, in the case of a 3 × 3\n",
    "matrix:\n",
    "##### tr(A) = a1;1 + a2;2 + a3;3\n",
    "\n",
    "###### We can calculate the trace of a matrix in NumPy using the trace() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square Matrix : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "_______________ \n",
      "Trace Matriix : \n",
      " 15\n"
     ]
    }
   ],
   "source": [
    "# matrix trace\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "\n",
    "print('Square Matrix : \\n',A)\n",
    "\n",
    "# calculate trace\n",
    "B = np.trace(A)\n",
    "print('_______________ \\nTrace Matriix : \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\n",
    "*\n",
    "#### Determinant |A|\n",
    "- The determinant of a square matrix is a scalar representation of the volume of the matrix.\n",
    "- More technically, the determinant is the product of all the eigenvalues of the matrix.\n",
    "- The intuition for the determinant is that it describes the way a matrix will scale another matrix when they are multiplied together.\n",
    "\n",
    "\n",
    "The determinant describes the relative geometry of the vectors that make up the\n",
    "rows of the matrix. More specifically, the determinant of a matrix A tells you the\n",
    "volume of a box with sides given by rows of A.\n",
    "###### It is denoted by the det(A) notation or |A|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A : \n",
      " [[1 2]\n",
      " [4 5]]\n",
      "determinant |A|  -2.9999999999999996\n",
      "__________________\n",
      "Matrix X : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "determinant |X|  -9.51619735392994e-16\n"
     ]
    }
   ],
   "source": [
    "# matrix determinant\n",
    "from numpy import array\n",
    "from numpy.linalg import det\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[4, 5]])\n",
    "\n",
    "X = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]]) \n",
    "\n",
    "# calculate determinant\n",
    "B = det(A)\n",
    "C = det(X)\n",
    "print('Matrix A : \\n',A)\n",
    "print('determinant |A| ',B)\n",
    "print('__________________\\nMatrix X : \\n',X)\n",
    "print('determinant |X| ',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "## Rank\n",
    "___________________________\n",
    "##### -The rank of a matrix is the estimate of the number of linearly independent rows or columns in a matrix.\n",
    "### Application on ML :\n",
    "##### *********** Computation the number of solution of a SYSTEM OF LINEAR EQUATION .\n",
    "##### *********** in the CONTROL theory, the rank of a matrix can be used to detrmine wether a LINEAR SYSTEM is CONTROLLABLE or OBSERVABLE .\n",
    "##### the system is inconsistent if the Rank of the argument matrix IS GREATER THAN the rank of the coefficient matrix . \n",
    "##### >> if on the other hand, the rank of these two matrices are Equal then\n",
    "##### -------------- THE SYSTEM MUST HAVE AT LEAST ONE SOLUTION , \n",
    "##### the solution is UNIQUE if and only if the rank equals the number of the variables  \n",
    "##### Otherwise in the general solution han K free Parameters where K is the diff. bet. the number of variables and the rank ,, in this case (system quations in real or complex number) \n",
    "##### the system of Equations HSE INFINTE MANY SOLUTIONS   \n",
    "||||||||\n",
    "- The rank of a matrix M is often denoted as the function rank(). \n",
    "- A common approach is to use the Singular-Value Decomposition or SVD for short. \n",
    "### NumPy provides the matrix rank() function for calculating the rank of an array. It uses the SVD method to estimate the rank.\n",
    "\n",
    "##### The example below demonstrates calculating the rank of a matrix with scalar values and another vector with all zero values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 1:-demonstrates calculating the rank of a matrix with scalar values and another vector with all zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector-one : \n",
      " [1 2 3]\n",
      "calculating the rank of Vector-One =  \n",
      " 1\n",
      "============================== \n",
      "Vector-Two :\n",
      " [0 0 0 0 0]\n",
      "calculating the rank of Vector-Two =  \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# vector rank\n",
    "\n",
    "from numpy.linalg import matrix_rank\n",
    "# rank\n",
    "v1 = np.array([1,2,3])\n",
    "print('Vector-one : \\n',v1)\n",
    "vr1 = matrix_rank(v1)\n",
    "print('calculating the rank of Vector-One =  \\n',vr1)\n",
    "# zero rank\n",
    "v2 = np.array([0,0,0,0,0])\n",
    "print('============================== \\nVector-Two :\\n',v2)\n",
    "vr2 = matrix_rank(v2)\n",
    "print('calculating the rank of Vector-Two =  \\n',vr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 2:-The next example makes it clear that the rank is not the number of dimensions of the matrix, but the number of linearly independent directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix one : \n",
      " [[0 0]\n",
      " [0 0]]\n",
      "Matrix Rank :: \n",
      " 0\n",
      "____________________\n",
      " Matrix two : \n",
      " [[  1   2 100   6]\n",
      " [  2   4  90  12]]\n",
      "Matrix Rank : \n",
      " 2\n",
      "____________________ \n",
      "Matrix Three : \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [1 2]]\n",
      "MAtrix Rank 2\n"
     ]
    }
   ],
   "source": [
    "# matrix rank\n",
    "from numpy.linalg import matrix_rank\n",
    "# rank 0\n",
    "M0 = np.array([\n",
    "[0,0],\n",
    "[0,0]])\n",
    "print('Matrix one : \\n',M0)\n",
    "mr0 = matrix_rank(M0)\n",
    "print('Matrix Rank :: \\n',mr0)\n",
    "# rank 1\n",
    "M1 = np.array([\n",
    "[1,2,100,6],\n",
    "[2,4,90,12]])\n",
    "print('____________________\\n Matrix two : \\n',M1)\n",
    "mr1 = matrix_rank(M1)\n",
    "print('Matrix Rank : \\n',mr1)\n",
    "# rank 2\n",
    "M2 = np.array([\n",
    "[1,2],\n",
    "[3,4],\n",
    "[1,2]])\n",
    "print('____________________ \\nMatrix Three : \\n',M2)\n",
    "mr2 = matrix_rank(M2)\n",
    "print('MAtrix Rank',mr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "______________________\n",
    "### SPARSE Matrices\n",
    "______________________\n",
    "\n",
    "##### SPARSE Matrices : Matrices that contain mostly zero values\n",
    "##### ON THE OTHER HND > DENSE : distinct from matrices where most of the values are non-zero.\n",
    "\n",
    "### Application on ML :\n",
    "##### Large sparse matrices are common in general and especially in applied machine learning, such as in data that contains counts, data encodings\n",
    "##### that map categories to counts, and even in whole subfields of machine learning such as natural language processing. \n",
    "**\n",
    "\n",
    "It is computationally expensive to represent and work with sparse matrices\n",
    "as though they are dense, and much improvement in performance can be achieved by using\n",
    "representations and operations that specifically handle the matrix sparsity. \n",
    "##### The sparsity of a matrix can be quantified with a[ S C O R E ] , which is the number of zero values in the matrix divided by the total number of elements in the matrix.\n",
    "- sparsity = count of non-zero elements / total elements\n",
    "\n",
    "### !!Problems with Sparsity_______________\n",
    "- Sparse matrices and the issues they present can cause problems with regards to \n",
    "### Space Complexity - time complexity.\n",
    "\n",
    "\n",
    "- problem with representing these sparse matrices as dense matrices is that memory is required\n",
    "and must be allocated for each 32-bit or even 64-bit zero value in the matrix. This is clearly a\n",
    "waste of memory resources as those zero values do not contain any information.\n",
    "- operations across this matrix may take a long time where the bulk of the computation performed will involve adding or multiplying zero values together.\n",
    "\n",
    "In practice, most large matrices are sparse | almost all entries are zeros.\n",
    "\n",
    "### !How to Working with Sparse Matrices\n",
    "- use an alternate data structure to represent the sparse data.\n",
    "- The zero values can be ignored and only the data or non-zero values in the sparse matrix need to be stored or acted upon.\n",
    "- There are multiple data structures that can be used to efficiently construct a sparse matrix; three common examples are listed below .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the example below, we define a 3×6 sparse matrix as a dense array (e.g. an ndarray), convert it to a CSR sparse representation, and then convert it back to a dense array by calling the todense() function\n",
    "\n",
    "!!!!!!!! CSR method : is to extract the non-zero values from dense matrix With the address of each value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dense Matrix ....  \n",
      " [[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n",
      "\n",
      "convert to sparse matrix (CSR method) ............ \n",
      "   (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 3)\t2\n",
      "\n",
      "reconstruct dense matrix ______________\n",
      " [[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "# create dense matrix\n",
    "A = array([\n",
    "[1, 0, 0, 1, 0, 0],\n",
    "[0, 0, 2, 0, 0, 1],\n",
    "[0, 0, 0, 2, 0, 0]])\n",
    "\n",
    "print('The dense Matrix ....  \\n',A)\n",
    "\n",
    "# convert to sparse matrix (CSR method)\n",
    "S = csr_matrix(A)\n",
    "print('\\nconvert to sparse matrix (CSR method) ............ \\n', S)\n",
    "# reconstruct dense matrix\n",
    "B = S.todense()\n",
    "print('\\nreconstruct dense matrix ______________\\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then how gto work wuith Sparity matrix >>>\n",
    "The example below demonstrates how to calculate the sparsity of an array.\n",
    "\n",
    "NumPy does not provide a function to calculate the sparsity of a matrix. Nevertheless, we\n",
    "can calculate it easily by first finding the density of the matrix and subtracting it from one. The\n",
    "number of non-zero elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense matrix ..........\n",
      " [[1 0 0 1 0 0]\n",
      " [0 0 2 0 0 1]\n",
      " [0 0 0 2 0 0]]\n",
      "\n",
      "__________________ \n",
      "calculate sparsity .......\n",
      " 0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "# sparsity calculation\n",
    "\n",
    "# create dense matrix\n",
    "A = np.array([\n",
    "[1, 0, 0, 1, 0, 0],\n",
    "[0, 0, 2, 0, 0, 1],\n",
    "[0, 0, 0, 2, 0, 0]])\n",
    "print('dense matrix ..........\\n',A)\n",
    "\n",
    "# calculate sparsity\n",
    "sparsity = 1.0 - count_nonzero(A) / A.size\n",
    "print('\\n__________________ \\ncalculate sparsity .......\\n',sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "____________________________________________\n",
    "## Tensors and Tensor Arithmetic\n",
    "__________________________________________\n",
    "#### - A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.\n",
    "#### - an array of numbers arranged on a regular grid with a variable number of axes.\n",
    "\n",
    "##### in Python using the N-dimensional array (ndarray). A tensor can be defined in-line to the constructor of array() as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tesor ______ \n",
      " (3, 3, 3)\n",
      "\n",
      " ---------------------\n",
      "Tensor 3*3*3 \n",
      " [[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "# create tensor\n",
    "\n",
    "T = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "print('The shape of the tesor ______ \\n',T.shape)\n",
    "print('\\n ---------------------\\nTensor 3*3*3 \\n',T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ----------- Tensor Arithmetic\n",
    "___________\n",
    "Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________\n",
      "The result of the Adding operatiopn \n",
      " [[[ 2  4  6]\n",
      "  [ 8 10 12]\n",
      "  [14 16 18]]\n",
      "\n",
      " [[22 24 26]\n",
      "  [28 30 32]\n",
      "  [34 36 38]]\n",
      "\n",
      " [[42 44 46]\n",
      "  [48 50 52]\n",
      "  [54 56 58]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor addition\n",
    "\n",
    "# define first tensor\n",
    "A = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# define second tensor\n",
    "B = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# add tensors\n",
    "C = A + B\n",
    "#print('First tensor \\n' , A)\n",
    "#print('\\nSecond tensor \\n', B)\n",
    "print('________________________\\nThe result of the Adding operatiopn \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "Tensor Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Result of the Subtraction Operation \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor subtraction\n",
    "\n",
    "# define first tensor\n",
    "A = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# define second tensor\n",
    "B = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# subtract tensors\n",
    "C = A - B\n",
    "print('The Result of the Subtraction Operation \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "Tensor Division ( C = A/B )\n",
    "##### The element-wise division of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise division of the scalars in the parent tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Resulted Divided tesnsors \n",
      "--------------------------------\n",
      "  [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor division\n",
    "from numpy import array\n",
    "# define first tensor\n",
    "A = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# define second tensor\n",
    "B = array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# divide tensors\n",
    "C = A / B\n",
    "print('The Resulted Divided tesnsors \\n--------------------------------\\n ',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "#### Tensor Hadamard Product ( C = A ◦ B )\n",
    "#### The element-wise multiplication of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise multiplication of the scalars in the parent tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the multiply tensors (Tensor Hadamard Product) \n",
      " [[[  1   4   9]\n",
      "  [ 16  25  36]\n",
      "  [ 49  64  81]]\n",
      "\n",
      " [[121 144 169]\n",
      "  [196 225 256]\n",
      "  [289 324 361]]\n",
      "\n",
      " [[441 484 529]\n",
      "  [576 625 676]\n",
      "  [729 784 841]]]\n"
     ]
    }
   ],
   "source": [
    "# tensor Hadamard product\n",
    "\n",
    "# define first tensor\n",
    "A = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# define second tensor\n",
    "B = np.array([\n",
    "[[1,2,3], [4,5,6], [7,8,9]],\n",
    "[[11,12,13], [14,15,16], [17,18,19]],\n",
    "[[21,22,23], [24,25,26], [27,28,29]]])\n",
    "# multiply tensors\n",
    "C = A * B\n",
    "print('The result of the multiply tensors (Tensor Hadamard Product) \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ====> Tensor Product ( C = a ⊗ b )\n",
    "###### C =\n",
    "###### [a1*b1 - a1*b2]\n",
    "###### [a2*b1 -  a2*b2]\n",
    "Given a tensor A with q dimensions and tensor B with r dimensions, the\n",
    "product of these tensors will be a new tensor with the order of q + r or, said another way, q + r\n",
    "dimensions.\n",
    "\n",
    "##### The tensor product can be implemented in NumPy using the tensordot() function\n",
    "the axis must be set to 0. In the example below, we define two order-1\n",
    "tensors (vectors) with and calculate the tensor product.\n",
    "\n",
    "to calculate the tensor product, also called the tensor\n",
    "dot product in NumPy, \n",
    "\n",
    "Three common use cases are:\n",
    "    \n",
    "    * ``axes = 0`` : tensor product :math:`a\\otimes b`\n",
    "    \n",
    "    * ``axes = 1`` : tensor dot product :math:`a\\cdot b`\n",
    "    \n",
    "    * ``axes = 2`` : (default) tensor double contraction :math:`a:b`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Vector \n",
      " [1 2]\n",
      "The first Vector \n",
      " [3 4]\n",
      "\n",
      "The Resulted tensor product \n",
      " [[3 4]\n",
      " [6 8]]\n"
     ]
    }
   ],
   "source": [
    "# tensor product\n",
    "\n",
    "from numpy import tensordot\n",
    "# define first vector\n",
    "A = np.array([1,2])\n",
    "# define second vector\n",
    "B = np.array([3,4])\n",
    "# calculate tensor product\n",
    "C = tensordot(A, B, axes=0)\n",
    "print('The first Vector \\n',A)\n",
    "print('The first Vector \\n',B)\n",
    "print('\\nThe Resulted tensor product \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization\n",
    "-  Matrix Decompositions\n",
    "- Eigendecomposition\n",
    "- Singular Value Decomposition\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decomposition - matrix factorization\n",
    "= is a way of reducing a matrix into its constituent parts. It is an\n",
    "approach that can simplify more complex matrix operations that can be performed on the\n",
    "decomposed matrix rather than on the original matrix itself\n",
    "\n",
    "Matrix decompositions are a useful tool for reducing a matrix to their constituent parts in\n",
    "order to simplify a range of more complex operations.\n",
    "\n",
    "- methods that reduce a matrix into constituent parts that make it easier to calculate more complex matrix operations. \n",
    "### Two simple and widely used matrix decomposition methods \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) LU Decomposition ( A = L · U . P )\n",
    "##### The LU decomposition is for square matrices and decomposes a matrix into L and U components.\n",
    "The factors L and U are triangular matrices.\n",
    "\n",
    "\n",
    "- where P is a permutation matrix, \n",
    "- L lower triangular with unit\n",
    "- diagonal elements, and U upper triangular\n",
    "#### A variation of this decomposition that is numerically more stable to solve in practice is called\n",
    "#### the LUP decomposition, or the LU decomposition with partial pivoting .\n",
    "\n",
    "implemented in Python with the lu() function. More\n",
    "specifically, this function calculates an LPU decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Square Matrix ...........\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "P is a permutation matrix : \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "\n",
      "L lower triangular with unit diagonal elements : \n",
      " [[1.         0.         0.        ]\n",
      " [0.14285714 1.         0.        ]\n",
      " [0.57142857 0.5        1.        ]]\n",
      "\n",
      " U upper triangular : \n",
      " [[ 7.00000000e+00  8.00000000e+00  9.00000000e+00]\n",
      " [ 0.00000000e+00  8.57142857e-01  1.71428571e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.58603289e-16]]\n",
      "_________________________________________________\n",
      "reconstruct The Decomposition Process \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# LU decomposition\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# define a square matrix\n",
    "A = array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print('The Square Matrix ...........\\n',A)\n",
    "\n",
    "# factorize\n",
    "P, L, U = lu(A)\n",
    "# where P is a permutation matrix, L lower triangular with unit\n",
    "# diagonal elements, and U upper triangular\n",
    "print('\\nP is a permutation matrix : \\n',P)\n",
    "print('\\nL lower triangular with unit diagonal elements : \\n',L)\n",
    "print('\\n U upper triangular : \\n',U)\n",
    "\n",
    "# reconstruct\n",
    "B = P.dot(L).dot(U)\n",
    "print('_________________________________________________\\nreconstruct The Decomposition Process \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) QR Decomposition ( A = Q · R )\n",
    "##### The QR decomposition is for n × m matrices (not limited to square matrices) and decomposes a matrix into Q and R components.\n",
    "Q a matrix with the size m×m, and R is an upper triangle matrix with the size m × n.\n",
    "#### Like the LU decomposition, the QR decomposition is often used to solve systems of linear equations, although is not limited to square matrices.\n",
    "\n",
    "implemented in NumPy using the qr() function\n",
    "Returns\n",
    "-------\n",
    "##### q :>>  ndarray of float or complex, optional A matrix with orthonormal columns. \n",
    "#### When mode = 'complete' the result is an orthogonal/unitary matrix depending on whether or not a is real/complex. The determinant may be either +/- 1 in that case.\n",
    "#####  r :>> ndarray of float or complex, optional The upper-triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Matrix ...........\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "Q >>>>>>>>>>>>>>>> \n",
      " [[-0.16903085  0.89708523  0.40824829]\n",
      " [-0.50709255  0.27602622 -0.81649658]\n",
      " [-0.84515425 -0.34503278  0.40824829]]\n",
      "\n",
      "R >>>>>>>>>>>>>>>> \n",
      " [[-5.91607978 -7.43735744]\n",
      " [ 0.          0.82807867]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "_________________________________ \n",
      "reconstruct The original matrix \n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# QR decomposition\n",
    "from numpy.linalg import qr\n",
    "\n",
    "# define rectangular matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('The Original Matrix ...........\\n',A)\n",
    "# factorize\n",
    "Q, R = qr(A, 'complete')\n",
    "\"\"\"\n",
    "Signature: qr(a, mode='reduced')\n",
    "Docstring:\n",
    "Compute the qr factorization of a matrix.\n",
    "\n",
    "Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is\n",
    "upper-triangular.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : array_like, shape (M, N)\n",
    "    Matrix to be factored.\n",
    "    \n",
    "* 'reduced'  : returns q, r with dimensions (M, K), (K, N) (default)\n",
    "    * 'complete' : returns q, r with dimensions (M, M), (M, N)\n",
    "    * 'r'        : returns r only with dimensions (K, N)\n",
    "    * 'raw'      : returns h, tau with dimensions (N, M), (K,)\n",
    "    * 'full'     : alias of 'reduced', deprecated\n",
    "    * 'economic' : returns h from 'raw', deprecated.\n",
    "\"\"\"\n",
    "print(\"\\nQ >>>>>>>>>>>>>>>> \\n\",Q)\n",
    "print('\\nR >>>>>>>>>>>>>>>> \\n',R)\n",
    "# reconstruct\n",
    "B = Q.dot(R)\n",
    "print('\\n_________________________________ \\nreconstruct The original matrix \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "#### 3) Cholesky Decomposition ( A = L · L^T )\n",
    "Where A is the matrix being decomposed, \n",
    "\n",
    "L is the lower triangular matrix and \n",
    "\n",
    "L^T is the transpose of L.\n",
    "\n",
    "#### The decompose can also be written as the product of the upper triangularmatrix, for example:\n",
    "( A = UT · U )\n",
    "\n",
    "##### implemented in NumPy by calling the cholesky()\n",
    "function. The function only returns L as we can easily access the L transpose as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symmetrical matrix \n",
      " [[2 1 1]\n",
      " [1 2 1]\n",
      " [1 1 2]]\n",
      "factorize Cholesky decomposition \n",
      " [[1.41421356 0.         0.        ]\n",
      " [0.70710678 1.22474487 0.        ]\n",
      " [0.70710678 0.40824829 1.15470054]]\n",
      "\n",
      "_________________________________ \n",
      "reconstruct The original matrix \n",
      " [[2. 1. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Cholesky decomposition\n",
    "from numpy import array\n",
    "from numpy.linalg import cholesky\n",
    "# define symmetrical matrix\n",
    "A = array([\n",
    "[2, 1, 1],\n",
    "[1, 2, 1],\n",
    "[1, 1, 2]])\n",
    "print('symmetrical matrix \\n',A)\n",
    "# factorize\n",
    "L = cholesky(A)\n",
    "print('factorize Cholesky decomposition \\n',L)\n",
    "# reconstruct\n",
    "B = L.dot(L.T)\n",
    "print('\\n_________________________________ \\nreconstruct The original matrix \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "\n",
    "## Eigendecomposition\n",
    "Calculation of Eigendecomposition >>>>>>>\n",
    "\n",
    "The eigendecomposition can be calculated in\n",
    "NumPy using the eig() function\n",
    "\n",
    "Compute the eigenvalues and right eigenvectors of a square array.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : (..., M, M) array\n",
    "    Matrices for which the eigenvalues and right eigenvectors will\n",
    "    be computed\n",
    "\n",
    "Returns\n",
    "-------\n",
    "#####  ||| w : (..., M) array\n",
    "##### The eigenvalues, each repeated according to its multiplicity.\n",
    "##### The eigenvalues are not necessarily ordered. The resulting\n",
    "##### array will be of complex type, unless the imaginary part is\n",
    "##### zero in which case it will be cast to a real type. When `a`\n",
    "##### is real the resulting eigenvalues will be real (0 imaginary\n",
    "##### part) or occur in conjugate pairs\n",
    "\n",
    "#####  ||| v : (..., M, M) array\n",
    "#####     The normalized (unit \"length\") eigenvectors, such that the\n",
    "#####     column ``v[:,i]`` is the eigenvector corresponding to the\n",
    "#####     eigenvalue ``w[i]``.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Matrix A \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      " The EIGEN VALUE______________________________\n",
      "\n",
      " [ 1.61168440e+01 -1.11684397e+00 -9.75918483e-16]\n",
      "\n",
      "\n",
      " The EIGEN VAECTOR_____________________________\n",
      "\n",
      " [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "# eigendecomposition\n",
    "\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print('The Matrix A \\n' , A)\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "\n",
    "print('\\n The EIGEN VALUE______________________________\\n\\n',values)\n",
    "print('\\n\\n The EIGEN VAECTOR_____________________________\\n\\n',vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm an Eigenvector and Eigenvalue\n",
    "\n",
    "1) we will define a matrix\n",
    "\n",
    "2) calculate the eigenvalues and eigenvectors.\n",
    "\n",
    "3) test whether the first vector and value are in fact an eigenvalue and eigenvector for the matrix.\n",
    "\n",
    "\"\"\"\n",
    "The eigenvectors are returned as a matrix with the same dimensions as the parent matrix,\n",
    "where each column is an eigenvector, e.g. the first eigenvector is vectors[:, 0]. Eigenvalues\n",
    "are returned as a list, \n",
    "\"\"\"\n",
    "\n",
    "##### The example multiplies the original matrix with the first eigenvector and compares it to the first eigenvector multiplied by the first eigenvalue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Matrix \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "EIGEN VECTOR \" \n",
      " [ 1.61168440e+01 -1.11684397e+00 -9.75918483e-16] \n",
      "\n",
      "______________________multiplies the original matrix with the first eigenvector :  \n",
      " [ -3.73863537  -8.46653421 -13.19443305] \n",
      "\n",
      "______________________compares it to the first eigenvector multiplied by the first eigenvalue \n",
      " [ -3.73863537  -8.46653421 -13.19443305]\n"
     ]
    }
   ],
   "source": [
    "# confirm eigenvector\n",
    "\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "\n",
    "# confirm first eigenvector\n",
    "B = A.dot(vectors[:, 0])\n",
    "print('The Original Matrix \\n',A)\n",
    "print('EIGEN VECTOR \" \\n' , values ,'\\n')\n",
    "print('______________________multiplies the original matrix with the first eigenvector :  \\n',B , '\\n')\n",
    "C = vectors[:, 0] * values[0]\n",
    "print('______________________compares it to the first eigenvector multiplied by the first eigenvalue \\n',C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "#### Reconstruct Matrix\n",
    "First, the list of eigenvectors must be taken together as a matrix, where each vector\n",
    "becomes a row.\n",
    "\n",
    "The eigenvalues need to be arranged into a diagonal matrix. The NumPy\n",
    "diag() function can be used for this. \n",
    "\n",
    "Next, we need to calculate the inverse of the eigenvector\n",
    "matrix, \n",
    "which we can achieve with the inv() NumPy function. Finally, these elements need to\n",
    "be multiplied together with the dot() function.\n",
    "##### The example calculates the eigenvalues and eigenvectors again and uses them to reconstruct the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Matrix : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      " Eigen Vectors : \n",
      " [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n",
      "\n",
      " matrix from eigenvectors\n",
      " [[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n",
      "\n",
      " inverse of eigenvectors matrix \n",
      " [[-0.48295226 -0.59340999 -0.70386772]\n",
      " [-0.91788599 -0.24901003  0.41986593]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n",
      "\n",
      " diagonal matrix from eigenvalues \n",
      " [[ 1.61168440e+01  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.11684397e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.75918483e-16]]\n",
      "\n",
      " _____________________________\n",
      "reconstruct the original matrix \n",
      "(  B = (eigenvectors).(eigenvalues).(inverse eigenvectors matrix) ) : \n",
      "\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct matrix\n",
    "from numpy.linalg import inv\n",
    "\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print('Real Matrix : \\n',A)\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "print('\\n Eigen Vectors : \\n' , vectors )\n",
    "# create matrix from eigenvectors\n",
    "Q = vectors\n",
    "print('\\n matrix from eigenvectors\\n' , Q)\n",
    "\n",
    "# create inverse of eigenvectors matrix\n",
    "R = inv(Q)\n",
    "print('\\n inverse of eigenvectors matrix \\n' , R)\n",
    "\n",
    "# create diagonal matrix from eigenvalues\n",
    "L = np.diag(values)\n",
    "print('\\n diagonal matrix from eigenvalues \\n' , L)\n",
    "\n",
    "# reconstruct the original matrix\n",
    "B = Q.dot(L).dot(R)\n",
    "print('\\n _____________________________\\nreconstruct the original matrix \\n(  B = (eigenvectors).(eigenvalues).(inverse eigenvectors matrix) ) : \\n\\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition  SVD \n",
    "#### The singular value decomposition (SVD) provides another way to factorize a matrix, into singular vectors and singular values.\n",
    "#### The SVD allows us to discover some of the same kind of information as the eigendecomposition. However, the SVD is more generally applicable.\n",
    "#### __is a matrix decomposition method for reducing a matrix to its constituent parts in order to make certain subsequent matrix calculations simpler.\n",
    "\n",
    "#### A = U · Σ · V^T\n",
    "##### > Where A is the real n × m matrix that we wish to decompose\n",
    "##### > U is an m × m matrix == called the left-singular vectors of A,\n",
    "##### > Σ is an m × n diagonal matrix == singular values of the original matrix A.\n",
    "##### > V^T is the V transpose of an n × n matrix where T is a superscript. == called the right-singular vectors of A.\n",
    " - data reduction method in machine learning. \n",
    " - SVD can also be used in least squares linear regression . \n",
    " - image compression, and denoising data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Matrx : \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "U____________\n",
      " [[-0.2298477   0.88346102  0.40824829]\n",
      " [-0.52474482  0.24078249 -0.81649658]\n",
      " [-0.81964194 -0.40189603  0.40824829]]\n",
      "\n",
      "S____________\n",
      " [9.52551809 0.51430058]\n",
      "\n",
      "V____________\n",
      " [[-0.61962948 -0.78489445]\n",
      " [-0.78489445  0.61962948]]\n"
     ]
    }
   ],
   "source": [
    "# singular-value decomposition\n",
    "\n",
    "from scipy.linalg import svd\n",
    "# define a matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('The Original Matrx : \\n',A)\n",
    "\n",
    "# factorize\n",
    "U, s, V = svd(A)\n",
    "\n",
    "print('\\nU____________\\n',U)\n",
    "print('\\nS____________\\n',s)\n",
    "print('\\nV____________\\n',V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "#### Reconstruct Matrix\n",
    "######  The U, s, and V elements returned from the svd() cannot be multiplied directly.\n",
    "######  The s vector must be converted into a diagonal matrix using the diag() function\n",
    "###### We can achieve this by creating a new Σ matrix of all zero values that is m × n (e.g. more rows) and populate the first n × n part of the matrix with the square diagonal matrix calculated via diag()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________THe Original Matrix : \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      " create m x n Sigma matrix : \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "___populate Sigma with n x n diagonal matrix \n",
      " [9.52551809 0.51430058]\n",
      "\n",
      "_________________________reconstruct matrix :\n",
      " [[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct rectangular matrix from svd\n",
    "\n",
    "from scipy.linalg import svd\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('__________________________THe Original Matrix : \\n',A)\n",
    "\n",
    "# factorize\n",
    "U, s, V = svd(A)\n",
    "\n",
    "# create m x n Sigma matrix\n",
    "Sigma= np.zeros((A.shape[0], A.shape[1]))\n",
    "print('\\n create m x n Sigma matrix : \\n',Sigma)\n",
    "\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[1], :A.shape[1]] = np.diag(s)\n",
    "print('\\n___populate Sigma with n x n diagonal matrix \\n',s)\n",
    "\n",
    "# reconstruct matrix\n",
    "B = U.dot(Sigma.dot(V))\n",
    "print('\\n_________________________reconstruct matrix :\\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above complication with the Σ diagonal only exists with the case where m and n are\n",
    "not equal. The diagonal matrix can be used directly when reconstructing a square matrix, as\n",
    "follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________The Original Matrix : \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "_______________________________The reconstructed matrix : \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct square matrix from svd\n",
    "\n",
    "from scipy.linalg import svd\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2, 3],\n",
    "[4, 5, 6],\n",
    "[7, 8, 9]])\n",
    "print('_______________________________The Original Matrix : \\n',A)\n",
    "\n",
    "# factorize\n",
    "U, s, V = svd(A)\n",
    "\n",
    "# create n x n Sigma matrix\n",
    "Sigma = np.diag(s)\n",
    "\n",
    "# reconstruct matrix\n",
    "B = U.dot(Sigma.dot(V))\n",
    "print('_______________________________The reconstructed matrix : \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pseudoinverse (  Moore-Penrose inverse  )\n",
    "##### The pseudoinverse provides one way of solving the linear regression equation, specifically\n",
    "##### when there are more rows than there are columns, which is often the case. \n",
    "##### NumPy provides the function pinv() for calculating the pseudoinverse of a rectangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Original Matrix _____________\n",
      " [[0.1 0.2]\n",
      " [0.3 0.4]\n",
      " [0.5 0.6]\n",
      " [0.7 0.8]]\n",
      "\n",
      "______________________________________pseudoinverse : \n",
      " [[-1.00000000e+01 -5.00000000e+00  9.07607323e-15  5.00000000e+00]\n",
      " [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# pseudoinverse\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[0.1, 0.2],\n",
    "[0.3, 0.4],\n",
    "[0.5, 0.6],\n",
    "[0.7, 0.8]])\n",
    "print('The Original Matrix _____________\\n',A)\n",
    "# calculate pseudoinverse\n",
    "B = pinv(A)\n",
    "print('\\n______________________________________pseudoinverse : \\n',B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "####  The result is a matrix with a lower rank that is said to approximate the original matrix. \n",
    "#### To do this we can perform an SVD operation on the original data and select the top k largest singular values in Σ. \n",
    "#### These columns can be selected from Σ and the rows selected from V T .\n",
    "\n",
    "The example below demonstrates data reduction with the SVD. First a 3 × 10 matrix is\n",
    "defined, with more columns than rows. The SVD is calculated and only the first two features\n",
    "are selected. The elements are recombined to give an accurate reproduction of the original\n",
    "matrix. Finally the transform is calculated two different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Matrix: .... \n",
      " [[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [11 12 13 14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n",
      "reconstructed Matrix :.......\n",
      " [[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      " [21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]]\n",
      "______________transform one \n",
      " [[-18.52157747   6.47697214]\n",
      " [-49.81310011   1.91182038]\n",
      " [-81.10462276  -2.65333138]]\n",
      "______________transform two \n",
      " [[-18.52157747   6.47697214]\n",
      " [-49.81310011   1.91182038]\n",
      " [-81.10462276  -2.65333138]]\n"
     ]
    }
   ],
   "source": [
    "# data reduction with svd\n",
    "\n",
    "from scipy.linalg import svd\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1,2,3,4,5,6,7,8,9,10],\n",
    "[11,12,13,14,15,16,17,18,19,20],\n",
    "[21,22,23,24,25,26,27,28,29,30]])\n",
    "print('Real Matrix: .... \\n',A)\n",
    "\n",
    "# factorize\n",
    "U, s, V = svd(A)\n",
    "\n",
    "# create m x n Sigma matrix\n",
    "Sigma = np.zeros((A.shape[0], A.shape[1]))\n",
    "\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[0], :A.shape[0]] = np.diag(s)\n",
    "\n",
    "# select\n",
    "n_elements = 2\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "V = V[:n_elements, :]\n",
    "\n",
    "# reconstruct\n",
    "B = U.dot(Sigma.dot(V))\n",
    "print('reconstructed Matrix :.......\\n',B)\n",
    "\n",
    "# transform\n",
    "T = U.dot(Sigma)\n",
    "print('______________transform one \\n',T)\n",
    "T = A.dot(V.T)\n",
    "print('______________transform two \\n',T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn provides a TruncatedSVD class that implements this capability directly. The\n",
    "TruncatedSVD class can be created in which you must specify the number of desirable features\n",
    "or components to select, e.g. 2. Once created, you can fit the transform (e.g. calculate VkT )\n",
    "by calling the fit() function, then apply it to the original matrix by calling the transform()\n",
    "function. The result is the transform of A called T above. The example below demonstrates the\n",
    "TruncatedSVD class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real matrix: ....\n",
      " [[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [11 12 13 14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n",
      "\n",
      "transformed version of the matrix....... \n",
      " [[18.52157747  6.47697214]\n",
      " [49.81310011  1.91182038]\n",
      " [81.10462276 -2.65333138]]\n"
     ]
    }
   ],
   "source": [
    "# svd data reduction in scikit-learn\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1,2,3,4,5,6,7,8,9,10],\n",
    "[11,12,13,14,15,16,17,18,19,20],\n",
    "[21,22,23,24,25,26,27,28,29,30]])\n",
    "print('The real matrix: ....\\n',A)\n",
    "# create transform\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "# fit transform\n",
    "svd.fit(A)\n",
    "# apply transform\n",
    "result = svd.transform(A)\n",
    "print('\\ntransformed version of the matrix....... \\n',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "\n",
    "## Statistics\n",
    "- Introduction to Multivariate Statistics\n",
    "- Principal Component Analysis\n",
    "- Linear Regression\n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Multivariate Statistics\n",
    "#### Expected Value and Mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector ... \n",
      " [1 2 3 4 5 6]\n",
      "the mean of the values in the vector ..... \n",
      " 3.5\n"
     ]
    }
   ],
   "source": [
    "# vector mean\n",
    "\n",
    "# define vector\n",
    "v = np.array([1,2,3,4,5,6])\n",
    "print('Vector ... \\n',v)\n",
    "# calculate mean\n",
    "result = np.mean(v)\n",
    "print('the mean of the values in the vector ..... \\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________Full Matrix ...\n",
      " [[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "Columns mean values..... \n",
      " [1. 2. 3. 4. 5. 6.]\n",
      "Rows mean values....... \n",
      " [3.5 3.5]\n"
     ]
    }
   ],
   "source": [
    "# matrix means\n",
    "\n",
    "# define matrix\n",
    "M = np.array([\n",
    "[1 ,2 ,3 ,4 ,5 ,6 ],\n",
    "[1 ,2 ,3 ,4 ,5 ,6]])\n",
    "print('_______________Full Matrix ...\\n',M)\n",
    "# column means\n",
    "col_mean = np.mean(M, axis=0)\n",
    "print('Columns mean values..... \\n',col_mean)\n",
    "# row means\n",
    "row_mean = np.mean(M, axis=1)\n",
    "print('Rows mean values....... \\n',row_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "### Variance and Standard Deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector ....... \n",
      " [1 2 3 4 5 6]\n",
      "Vector Variance ....... \n",
      " 3.5\n"
     ]
    }
   ],
   "source": [
    "# vector variance\n",
    "\n",
    "# define vector\n",
    "v = np.array([1,2,3,4,5,6])\n",
    "print('Vector ....... \\n',v)\n",
    "# calculate variance\n",
    "result = np.var(v, ddof=1)\n",
    "\"\"\"ddof ::::-\n",
    "Delta Degrees of Freedom\": \n",
    "                         the divisor used in the calculation is\n",
    "                        ``N - ddof``, where ``N`` represents the number of elements. By default `ddof` is zero.\n",
    "\"\"\"\n",
    "print('Vector Variance ....... \\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Matrix..... \n",
      " [[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n",
      "\n",
      "Columns variances.... \n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "Rows variances ........ \n",
      " [3.5 3.5]\n",
      "\n",
      "column standard deviations ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      "row standard deviations .......\n",
      " [1.87082869 1.87082869]\n"
     ]
    }
   ],
   "source": [
    "# matrix variances\n",
    "# define matrix\n",
    "M = np.array([\n",
    "[1,2,3,4,5,6],\n",
    "[1,2,3,4,5,6]])\n",
    "print('Full Matrix..... \\n',M)\n",
    "# column variances\n",
    "col_var = np.var(M, ddof=1, axis=0)\n",
    "print('\\nColumns variances.... \\n',col_var)\n",
    "# row variances\n",
    "row_var = np.var(M, ddof=1, axis=1)\n",
    "print('Rows variances ........ \\n',row_var)\n",
    "\n",
    "# column standard deviations\n",
    "col_std = np.std(M, ddof=1, axis=0)\n",
    "print('\\ncolumn standard deviations ...\\n',col_std)\n",
    "# row standard deviations\n",
    "row_std = np.std(M, ddof=1, axis=1)\n",
    "print('row standard deviations .......\\n',row_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "\n",
    "### Covariance and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First vector......... \n",
      " [1 2 3 4 5 6 7 8 9]\n",
      "Second vector......... \n",
      " [9 8 7 6 5 4 3 2 1]\n",
      "\n",
      "covariance..... \n",
      " -7.5\n"
     ]
    }
   ],
   "source": [
    "# vector covariance\n",
    "\n",
    "# define first vector\n",
    "x = np.array([1,2,3,4,5,6,7,8,9])\n",
    "print('First vector......... \\n',x)\n",
    "# define second covariance\n",
    "y = np.array([9,8,7,6,5,4,3,2,1])\n",
    "print('Second vector......... \\n',y)\n",
    "\n",
    "# calculate covariance\n",
    "Sigma = np.cov(x,y)[0,1]\n",
    "print('\\ncovariance..... \\n',Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||||||\n",
    "* Correlation is a normalized measure of the amount and direction (positive or negative) that two columns change together.\n",
    "* Covariance is a generalized and unnormalized version of correlation across multiple columns. \n",
    "* A covariance matrix is a calculation of covariance of a given matrix with covariance scores for every column with every other column, including itself.\n",
    "\n",
    "|||||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first vector.............. \n",
      " [1 2 3 4 5 6 7 8 9]\n",
      "second vector............. \n",
      " [9 8 7 6 5 4 3 2 1]\n",
      "\n",
      "correlation Result ........... \n",
      " -1.0\n"
     ]
    }
   ],
   "source": [
    "# vector correlation\n",
    "\n",
    "# define first vector\n",
    "x = np.array([1,2,3,4,5,6,7,8,9])\n",
    "print('first vector.............. \\n',x)\n",
    "# define second vector\n",
    "y = np.array([9,8,7,6,5,4,3,2,1])\n",
    "print('second vector............. \\n',y)\n",
    "\n",
    "# calculate correlation\n",
    "corr = np.corrcoef(x,y)[0,1]\n",
    "print('\\ncorrelation Result ........... \\n',corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "\n",
    "### Covariance Matrix\n",
    "* A covariance matrix is a calculation of covariance of a given matrix with covariance scores for every column with every other column, including itself.\n",
    "\n",
    "\n",
    "And X is a matrix where each column represents a random variable. The covariance matrix\n",
    "provides a useful tool for separating the structured relationships in a matrix of random variables.\n",
    "This can be used to decorrelate variables or applied as a transform to other variables. It is a key\n",
    "element used in the Principal Component Analysis data reduction method, or PCA for short.\n",
    "The covariance matrix can be calculated in NumPy using the cov() function. By default,\n",
    "this function will calculate the sample covariance matrix. The cov() function can be called with\n",
    "a single 2D array where each sub-array contains a feature (e.g. column). If this function is called\n",
    "with your data defined in a normal matrix format (rows then columns), then a transpose of the\n",
    "matrix will need to be provided to the function in order to correctly calculate the covariance of\n",
    "the columns. Below is an example that defines a dataset with 5 observations across 3 features\n",
    "and calculates the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset with 5 observations across 3 features........... \n",
      " [[ 1  5  8]\n",
      " [ 3  5 11]\n",
      " [ 2  4  9]\n",
      " [ 3  6 10]\n",
      " [ 1  5 10]]\n",
      "\n",
      "_____________________calculate covariance matrix .......\n",
      " [[1.   0.25 0.75]\n",
      " [0.25 0.5  0.25]\n",
      " [0.75 0.25 1.3 ]]\n"
     ]
    }
   ],
   "source": [
    "# covariance matrix\n",
    "\n",
    "# define matrix of observations\n",
    "X = np.array([\n",
    "[1, 5, 8],\n",
    "[3, 5, 11],\n",
    "[2, 4, 9],\n",
    "[3, 6, 10],\n",
    "[1, 5, 10]])\n",
    "print('dataset with 5 observations across 3 features........... \\n',X)\n",
    "# calculate covariance matrix\n",
    "Sigma = np.cov(X.T)\n",
    "print('\\n_____________________calculate covariance matrix .......\\n',Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "\n",
    "## Principal Component Analysis ( PCA )\n",
    "P-C-A : An important machine learning method for dimensionality reduction \n",
    "\n",
    "It is a method that uses simple matrix operations from linear algebra and\n",
    "statistics to calculate a projection of the original data into the same number or fewer dimensions\n",
    "___________________________\n",
    "Calculate Principal Component Analysis\n",
    "##### There is no pca() function in NumPy but we can easily calculate the Principal Component Analysis step-by-step using NumPy functions ...\n",
    "- 1) calculate the mean values of each column >|||> M = mean(A)\n",
    "- 2) we need to center the values in each column by subtracting the mean column value >|||> C = A − M\n",
    "- 3) calculate the covariance matrix of the centered matrix C >|||> V = cov(C)\n",
    "- 4) we calculate the eigendecomposition of the covariance matrix V . This results in a list of eigenvalues and a list of eigenvectors >|||> values; vectors = eig( V )\n",
    "- 5) select k eigenvectors, called principal components, that have the k largest eigenvalues >|||>B = select(values; vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dc300eaca699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# define matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m A = np.array([\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# principal component analysis\n",
    "\n",
    "from numpy.linalg import eig\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('Full Original Matrix .........\\n',A)\n",
    "# 1) >>>>>>>>>>>>>>> column means\n",
    "M = np.mean(A.T, axis=1)\n",
    "# 2) >>>>>>>>>>>>>>> center columns by subtracting column means\n",
    "C = A - M\n",
    "# 3) >>>>>>>>>>>>>>> calculate covariance matrix of centered matrix\n",
    "V = np.cov(C.T)\n",
    "# 4) >>>>>>>>>>>>>>> factorize covariance matrix\n",
    "values, vectors = eig(V)\n",
    "print('\\nEigen Vectros........\\n',vectors)\n",
    "print('\\nEigen Values........\\n',values)\n",
    "\n",
    "# project data\n",
    "P = vectors.T.dot(C.T)\n",
    "print('_________________________________Final Results-projection of the original matrix- ............\\n',P.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "**\n",
    "\n",
    "## Principal Component Analysis in scikit-learn\n",
    "\n",
    "Principal component analysis (PCA)\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the\n",
    "data to project it to a lower dimensional space. The input data is centered\n",
    "but not scaled for each feature before applying the SVD.\n",
    "\n",
    "It uses the LAPACK implementation of the full SVD or a randomized truncated\n",
    "SVD by the method of Halko et al. 2009, depending on the shape of the input\n",
    "data and the number of components to extract.\n",
    "\n",
    "It can also use the scipy.sparse.linalg ARPACK implementation of the\n",
    "truncated SVD.\n",
    "\n",
    "#### n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'\n",
    "________________\n",
    "We can calculate a Principal Component Analysis on a dataset using the PCA() class in the scikit-learn library.\n",
    "\n",
    "- the number of components can be specified as a parameter. \n",
    "- The class is first fit on a dataset by calling the fit() function, \n",
    "- and then the original dataset or other data can be projected into a subspace with the chosen number of dimensions by calling the transform() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full MAtrix .......\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "principal components............... \n",
      " [[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "values .......................\n",
      " [8.00000000e+00 2.25080839e-33]\n",
      "\n",
      " projection of the original matrix ......... \n",
      " [[-2.82842712e+00  2.22044605e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 2.82842712e+00 -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "# principal component analysis with scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# define matrix\n",
    "A = np.array([\n",
    "[1, 2],\n",
    "[3, 4],\n",
    "[5, 6]])\n",
    "print('Full MAtrix .......\\n',A)\n",
    "\n",
    "# create the transform\n",
    "pca = PCA(2) # n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'\n",
    "\n",
    "# fit transform\n",
    "pca.fit(A)\n",
    "\n",
    "# access values and vectors\n",
    "print('\\nprincipal components............... \\n',pca.components_)\n",
    "print('values .......................\\n',pca.explained_variance_)\n",
    "\n",
    "# transform data\n",
    "B = pca.transform(A)\n",
    "\"\"\"\n",
    "Apply dimensionality reduction to A.\n",
    "\n",
    "A is projected on the first principal components previously extracted\n",
    "from a training set\n",
    "\n",
    "\"\"\"\n",
    "print('\\n projection of the original matrix ......... \\n',B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "## Linear Regression [ y = f(x) ]\n",
    "Linear regression is a method for modeling the relationship between two scalar values: the\n",
    "input variable x and the output variable y. The model assumes that y is a linear function or a\n",
    "weighted sum of the input variable.\n",
    "#### 1) y = f(x)\n",
    "\n",
    "### 2) y = b0 + (b1 × x1) + (b2 × x2) + · · ·\n",
    "The objective of creating a linear regression model is to find the values for the coefficient\n",
    "values (b) that minimize the error in the prediction of the output variable y.\n",
    "\n",
    "#### 3) y = X.b \n",
    "Where X is the input data and each column is a data feature, b is a vector of coefficients\n",
    "and y is a vector of output variables for each row in X.\n",
    "___________________\n",
    "- Linear Regression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real DataSet Matrix : \n",
      " [[0.05 0.12]\n",
      " [0.18 0.22]\n",
      " [0.31 0.35]\n",
      " [0.42 0.38]\n",
      " [0.5  0.49]]\n",
      "\n",
      "_____________________\n",
      " Inpits:\n",
      " [[0.05]\n",
      " [0.18]\n",
      " [0.31]\n",
      " [0.42]\n",
      " [0.5 ]] \n",
      "_________________________\n",
      " Outputs: \n",
      " [0.12 0.22 0.35 0.38 0.49] \n",
      "_____________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression dataset\n",
    "from numpy import array\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "data = array([\n",
    "[0.05, 0.12],\n",
    "[0.18, 0.22],\n",
    "[0.31, 0.35],\n",
    "[0.42, 0.38],\n",
    "[0.5, 0.49]])\n",
    "print('Real DataSet Matrix : \\n',data)\n",
    "\n",
    "# split into inputs and outputs\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "print('\\n_____________________\\n Inpits:\\n',X,'\\n_________________________\\n Outputs: \\n',y,'\\n_____________________')\n",
    "# scatter plot\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve via Inverse\n",
    "\n",
    "##### b = (X^T · X)−1 · X^T · y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAd3ElEQVR4nO3de3TU9Z3/8efbCCUVBVmoi9EaVES5RKMpVcup9bZ4WZEqemCXHlFZ6g9ZdMFYoOoqXigEikoRAUFRUBDlEmgwXDQiFZFwFzFKOSoktgQVvEUgyef3xye6EQKZyMx8Z77zepzDaWbmy8z7fE949e1nPhdzziEiIsnvqKALEBGR6FCgi4iEhAJdRCQkFOgiIiGhQBcRCYmjg/rgli1buszMzKA+XkQkKa1Zs2aXc65VXa8FFuiZmZkUFxcH9fEiIknJzD461GsachERCQkFuohISCjQRURCQoEuIhISCnQRkZBQoIuIhIQCXUQkJCIKdDO7wsxKzGyrmQ2p4/U+ZlZuZutr/vSNfqkiInI49Qa6maUB44ErgfZALzNrX8els5xz59T8eSrKdYqIJJcFC+Ddd+P6kZF06J2Brc65bc65fcBM4NrYliUikqR274Y+faBbNxg5Mq4fHUmgZwDbaz3eUfPcga43s41m9pKZnVzXG5lZPzMrNrPi8vLyH1GuiEgCKyiADh1g+nS4916YPDmuHx9JoFsdzx14bt0CINM5lwUsBabV9UbOuUnOuRznXE6rVnXuLSMiknz27IFbb4Wrr4bjj+e1aQv41U9/Q5v7lvCrP73KvHWlcSkjkkDfAdTuuE8Cympf4Jz71Dm3t+bhZOC86JQnIpLgFi+Gjh3hmWdg6FDyp+TT/z2jdHcFDijdXcHQOZviEuqRBPpqoK2ZtTGzxkBPIL/2BWbWutbDbsCW6JUoIpKAvvwSfv976NoVmjaFlSvhkUcY+dqHVOyv+sGlFfuryCssiXlJ9W6f65yrNLMBQCGQBkx1zm02s+FAsXMuHxhoZt2ASuAzoE8MaxYRCdayZX6IZft2yM2F4cOhSRMAynZX1PlXDvV8NEW0H7pzrgAoOOC5+2r9PBQYGt3SREQSzFdfwd13w4QJcMYZsGIFXHDBDy45sXk6pXWE94nN02NenlaKiohEoqgIsrLgySdh0CBYv/6gMAfI7dqO9EZpP3guvVEauV3bxbxEBbqIyOF8/TUMHAgXXwxpabB8OYwZA+l1d9zdszMYcV0nMpqnY0BG83RGXNeJ7tl1zfaOrsCOoBMRSXgrVvhFQn//uw/1Rx6BY46p9691z86IS4AfSB26iMiBvvnGD6v8+tdQXe2HWx57LKIwD5I6dBGR2lau9F35++9D//5++X7TpkFXFRF16CIiAN9+62ewdOkCe/f6qYnjxydNmIM6dBERePttuOkmeO89v1goLw+OPTboqhpMHbqIpK69e2HoUD/98OuvobDQT0tMwjAHdegikqqKi/1Y+ebNftXnmDHQrFnQVR0Rdegiklr27fNb255/Pnz+ud/y9qmnkj7MQR26iKSSdet8V75xo//fsWOhefOgq4oadegiEn7798MDD0DnzrBzpz8e7umnQxXmoA5dRMJu40Y/g2X9eujd2y8QatEi6KpiQh26iIRTZSU8/DDk5EBZGcydC889F9owB3XoIhJGmzf7rnzNGujZE8aNg5Ytg64q5tShi0h4VFb6pfrnngsffQSzZ8MLL6REmIM6dBEJiy1b/MyVt9+GHj38sv2f/SzoquJKHbqIJLeqKhg9GrKz/Ta3s2b5zjzFwhzUoYtIMnv/fd+Vr1wJ3bv7ZfsnnBB0VYFRhy4iyae6Gh59FM4+22+oNWMGzJmT0mEO6tBFJNls3Qq33AJvvAHXXAMTJ0Lr1kFXlRDUoYtIcqiu9tMPs7L8YqFp02D+fIV5LerQRSTxbdvmu/LXX4crr4TJkyEj/md2Jjp16CKSuKqrYcIE35WvWwdTpsBf/6owPwR16CKSmD76yO9TvmwZ/Nu/+S1uTz456KoSmjp0EUkszvkhlY4dYdUqmDQJXnlFYR4Bdegikji2b4e+fWHxYrjkEpg6FU45JeiqkoY6dBEJnnN+f/KOHeFvf4MnnoAlSxTmDaQOXUSCVVoK/fr5o+Auush35aeeGnRVSUkduogEwzl49lno0AGKivwc81dfVZgfAXXoIhJ/n3wCv/+9PwquSxc/3HL66UFXlfTUoYtI/DgHzz/vu/IlS/whzUVFCvMoUaCLSHz8859w/fXwn/8JZ54JGzbAnXdCWlrQlYWGAl1EYm/WLN+VFxRAXp7fWOuMM4KuKnQiCnQzu8LMSsxsq5kNOcx1PczMmVlO9EoUkaRVXg433ujP9TztNL98/6671JXHSL2BbmZpwHjgSqA90MvM2tdx3bHAQGBVtIsUkST08su+K58/H0aM8PPLzzor6KpCLZIOvTOw1Tm3zTm3D5gJXFvHdQ8Co4Bvo1ifiCSbTz+FXr38uZ4//zmsXQtDhsDRmlQXa5EEegawvdbjHTXPfc/MsoGTnXMLD/dGZtbPzIrNrLi8vLzBxYpIgps/33flL78MDz3kj4br0CHoqlJGJIFudTznvn/R7ChgLDC4vjdyzk1yzuU453JatWoVeZUiktg++wx+9zt/rmfr1lBcDH/8IzRqFHRlKSWSQN8B1N7m7CSgrNbjY4GOQJGZfQicD+Tri1GRFLFwod+DZeZMuP9+ePttv3+5xF0kgb4aaGtmbcysMdATyP/uRefcHudcS+dcpnMuE3gL6OacK45JxSKSGHbvhj59/LmeLVv6IP/f/1VXHqB6A905VwkMAAqBLcCLzrnNZjbczLrFukARSUCLFvmufPp0uOceP8SSnR10VSkvoq+dnXMFQMEBz913iGt/c+RliUhC2rMHBg/2R8F16ADz5kGORlcTheYRiUhklizxR8KVlsLQoX545Sc/icpbz1tXSl5hCWW7KzixeTq5XdvRPVvnhjaUAl1EDu/LLyE3FyZO9HuwrFwJnTtH7e3nrStl6JxNVOyvAqB0dwVD52wCUKg3kPZyEZFDe/VV6NTJn+uZm+uX7kcxzAHyCku+D/PvVOyvIq+wJKqfkwoU6CJysK++gttvh0sv9cMqK1bAqFHQpEnUP6psd0WDnpdDU6CLyA+9/rqfRz5hAgwaBOvXw4UXxuzjTmye3qDn5dAU6CLiff013HEH/OY3cNRRsHw5jBkD6bEN1tyu7Uhv9MPdF9MbpZHbtV1MPzeM9KWoiPghlZtvhq1bYeBAeOQROOaYuHz0d198apbLkVOgi6Syigq/58qjj0JmJrz2mu/Q46x7doYCPAoU6CKpauVKv3T//fehf38YORKaNg26KjkCGkMXSTXffgt33w1duvifly6F8eMV5iGgDl0klbz9Ntx0E7z3HvTr58/3PO64oKuSKFGHLpIK9u6FYcPgggv8bJbCQr/yU2EeKurQRcJuzRrflW/e7PdiGTMGmjULuiqJAQW6SBwEsvnUvn3w4IP+gOYTToCCArjyyth+pgRKgS4SY4FsPrVunZ/BsnGj787HjoXjj4/NZ0nC0Bi6SIzFdfOp/fvhgQf8Blo7d0J+PjzzjMI8RahDF4mxuG0+tXGj78rXrYPeveGxx6BFi+h+hiQ0degiMRbzzacqK+Hhh/3JQaWlMHcuPPecwjwFKdBFYiymm09t3gznn+/P9bz+ev+4e/cjf19JSgp0kRjrnp3BiOs6kdE8HQMymqcz4rpOR/aFaGWlX6p/7rnw0Ucweza88AK0bBm1uiX5aAxdJA6iuvnUli1+rPztt31X/sQT8LOfRee9JampQxdJFlVVMHo0ZGf7bW5nzvSducJcaqhDF0kG77/vu/KVK/0Y+YQJ8K//GnRVkmDUoYsksqoqvyjo7LP9hlozZsCcOQpzqZM6dJFEtXWrP0VoxQr493+HSZOgdeugq5IEpg5dJNFUV8O4cf6g5k2bYNo0v+JTYS71UIcukki2bYNbboHXX/cbaU2eDBk6mk0iow5dJBFUV/svOrOy/NL9KVPgr39VmEuDqEMXCdpHH/l9ypctg8svh6eegp//POiqJAmpQxcJinN+SKVjR1i1yp8gVFioMJcfTR26SBC2b4e+fWHxYrjkEj/EkpkZdFWS5NShi8STczB1qu/K//Y3v2x/yRKFuUSFOnSReCkthf/6L1i0CC66yAf7qacGXZWEiDp0kVhzzs8l79ABiorg8cfh1VcV5hJ16tBFYumTT6BfP1i4ELp0gaefhtNPD7oqCamIOnQzu8LMSsxsq5kNqeP128xsk5mtN7MVZtY++qWKJBHn/L4rHTrA0qV+P5aiIoW5xFS9gW5macB44EqgPdCrjsB+3jnXyTl3DjAK+HPUKxVJFv/8J1x3nT/X88wzYf16uPNOSEur/++KHIFIOvTOwFbn3Dbn3D5gJnBt7Qucc1/UengM4KJXokiScA5mzfJd+aJFkJcHb7wB7aJw1JxIBCIZQ88Attd6vAP45YEXmdntwCCgMXBJXW9kZv2AfgA/1+IJCZPycujfH156CTp3hmeegbPOCroqSTGRdOhWx3MHdeDOufHOudOAPwD31PVGzrlJzrkc51xOq1atGlapSKJ6+WXflefnw4gRfn65wlwCEEmg7wBOrvX4JKDsMNfPBHTsuITfrl3Qsyf06OGX669ZA0OGwNGaPCbBiCTQVwNtzayNmTUGegL5tS8ws7a1Hl4NfBC9EkUS0Lx5viufMwceesgfDdexY9BVSYqrt5VwzlWa2QCgEEgDpjrnNpvZcKDYOZcPDDCzy4D9wOfATbEsWiQwn30GAwf6KYnnnOOX7WdlBV2VCBDhwiLnXAFQcMBz99X6+Y4o1yWSeBYs8IuEdu2C+++HYcOgUaOgqxL5ngb7ROqze7efRz5tGnTqBAUFkJ0ddFUiB9FeLiKHs2iRHyufPh3uuQeKixXmkrAU6CJ12bPHnyJ01VXQvDm89RY8+CA0bhx0ZSKHpEAXOdDixX7GyjPPwNChsHYt5OQEXZVIvTSGLvKdL7+Eu+6CSZP8HiwrV/pVnyJJQh26CPgDmjt18md85ubCunUKc0k6CnRJbV995fdguewy+MlPYMUKGDUKmjQJujKRBlOgS+oqKvKLgp58EgYN8tvcXnhh0FWJ/GgKdEk9X3/tV3tefDEcdRQsXw5jxkB6etCViRwRBbqkljfegLPPhnHjfKhv2OCPhhMJAQW6pIZvvvHDKhddBNXVfrjlscfgmGOCrkwkajRtUcJv5Uro0wfef99/ATpyJDRtGnRVIlGnDl3Cq6LCT0Hs0gW+/dYf1jx+vMJcQksduoTTqlW+K3/vPb9DYl4eHHdc0FWJxJQ6dAmXvXv9cv0LL/SzWQoLYeJEhbmkBHXoEh7Fxb4r37zZb6w1Zgw0axZ0VSJxow5dkt/evX5r2/PPh88/9/uVP/WUwlxSjjp0SW7r1sFNN8GmTb47HzvWb3crkoLUoUty2r8fHnjAb6BVXu6Ph3v6aYW5pDR16JJ8Nmzw3fj69dC7t18g1KJF0FWJBE4duiSP/fvhoYfgF7+AsjKYOxeee05hLlJDHbokh3fe8V35mjXQs6ffi6Vly6CrEkko6tAlsVVWwogRcN558PHH8NJL8MILCnOROqhDl8S1ZYufwbJ6NfToAU88Aa1aBV2VSMJShy6Jp6rKL9XPzoZt22DWLJg9W2EuUg916JJYSkrg5pv9Dondu/vThE44IeiqRJKCAl3qNG9dKXmFJZTtruDE5unkdm1H9+yM2H1gVRU8/jgMG+ZPDpoxA3r1ArPYfaZIyCjQ5SDz1pUydM4mKvZXAVC6u4KhczYBxCbUt271XfmKFXDNNX4zrdato/85IiGnMXQ5SF5hyfdh/p2K/VXkFZZE94Oqq31XnpXll+5Pmwbz5yvMRX4kdehykLLdFQ16/kfZts135cuXw1VXwaRJkBHDIR2RFKAOXQ5yYvP0Bj3fINXVfvphVpZfuj91KixcqDAXiQIFuhwkt2s70hul/eC59EZp5HZtd2Rv/OGHcPnlcPvt8Ktf+dWfN9+sLz5FokRDLnKQ7774jNosF+f8kMpdd/nwnjQJ+vZVkItEmQJd6tQ9OyM6M1o+/tiH95IlcOmlMGUKnHLKkb+viBwkoiEXM7vCzErMbKuZDanj9UFm9q6ZbTSzZWamf7Gpzjkf3h07wptvwoQJPtQV5iIxU2+gm1kaMB64EmgP9DKz9gdctg7Icc5lAS8Bo6JdqCSRHTv8zJW+ff2mWps2wW23aYhFJMYi6dA7A1udc9ucc/uAmcC1tS9wzr3mnPum5uFbwEnRLVOSgnN+LnnHjn464rhxsGwZtGkTdGUiKSGSQM8Attd6vKPmuUO5FVh0JEVJEiorg27d/J7lnTr5U4UGDICjNJFKJF4i+ddW138nuzovNOsN5AB5h3i9n5kVm1lxeXl55FVK4nIOpk/3XfnSpf6Q5tdfh9NPD7oykZQTSaDvAE6u9fgkoOzAi8zsMuCPQDfn3N663sg5N8k5l+Ocy2mlrVCT3z/+Ab/9Lfzud3DWWb4rv/NOdeUiAYnkX95qoK2ZtTGzxkBPIL/2BWaWDUzEh/nO6JcpCcU5mDkTOnSAV16B0aP9mPkZZwRdmUhKqzfQnXOVwACgENgCvOic22xmw82sW81leUBTYLaZrTez/EO8nSS7nTvhhhv81rann+6X7w8eDGlp9f9dEYmpiBYWOecKgIIDnruv1s+XRbkuSUSzZ0P//vDFF/CnP/kgP1pr00QShQY7pX67dkHPnnDjjZCZCWvXwh/+oDAXSTAKdDm8uXP9WPmcOfDww/5ouA4dgq5KROqgFkvq9umnMHAgPP+8P6x5yRK/5a2IJCx16HKw/Hw/r/zFF+H++2HVKoW5SBJQhy7/5/PP/TzyZ5/1Ab5oEZxzTtBViUiE1KGLV1Dgu/IZM+Dee2H1aoW5SJJRoKe6PXvgllvg6qvh+OP98Mrw4dC4cdCViUgDKdBTWWGh78qnTYNhw2DNGr/drYgkJY2hp6IvvvDHwU2e7PdgWbkSOncOuioROULq0FPN0qV+e9spU+Duu/0iIYW5SCgo0FPFV1/5ZfuXXw5NmsCKFTBypP9ZREJBgZ4Kiop8V/7kkzBokN9Q64ILgq5KRKJMgR5mX38N//3fcPHFft+V5cthzBhITw+6MhGJAQV6WL3xhl8c9Je/wB13+MMnunQJuioRiSEFeth88w38z//ARRf5x0VF8Oij8NOfBlqWiMSepi2GyZtv+kOaP/gAbr/d71netGnQVYlInKhDD4OKCsjN9UMq+/bBsmV+qEVhLpJS1KEnu1Wr4KaboKQEbrsNRo2CY48NuioRCYA69GT17bcwZAhceKEfN1+8GCZMUJiLpDB16MmouNh35e++C337wujR0KxZ0FWJSMDUoSeTvXvhnnvg/PP9LokFBX4/FoW5iKAOPXmsXetnsGza5P937Fho3jzoqkQkgahDT3T79vlj4H75S9i1CxYsgKefVpiLyEHUoSeyDRt8N75+PfTuDY89Bi1aBF2ViCQodeiJaP9+ePBByMmBTz6BefPguecU5iJyWOrQE8077/gZLGvXQq9eMG4c/Mu/BF2ViCSBUAT6vHWl5BWWULa7ghObp5PbtR3dszOCLqthKishL8+PlzdrBi+9BNdfH3RVIpJEkj7Q560rZeicTVTsrwKgdHcFQ+dsAkieUH/3XT9Wvno13HADjB8PrVoFXZWIJJmkH0PPKyz5Psy/U7G/irzCkoAqaoCqKt+Vn3subNsGs2bBiy8qzEXkR0n6Dr1sd0WDnk8YJSW+K3/rLfjtb/2y/RNOCLoqEUliSd+hn9i87tN3DvV84Kqq4M9/hnPO8aE+Ywa8/LLCXESOWNIHem7XdqQ3SvvBc+mN0sjt2i6gig7jgw/8wRODB/vDmjdvhv/4DzALujIRCYGkD/Tu2RmMuK4TGc3TMSCjeTojruuUWF+IVlfD44/D2Wf7EH/2WZg/H1q3DroyEQmRpB9DBx/qCRXgtW3bBjff7A9ovuoqmDQJMhK0VhFJaknfoSes6mo//TAryy/dnzoVFi5UmItIzEQU6GZ2hZmVmNlWMxtSx+u/NrO1ZlZpZj2iX2aS+fBDuOwyGDDAHwv3zju+S9dYuYjEUL2BbmZpwHjgSqA90MvM2h9w2cdAH+D5aBeYVJyDiROhUyd/CMXkybBoEZx8ctCViUgKiGQMvTOw1Tm3DcDMZgLXAu9+d4Fz7sOa16pjUGNy+Phjf3rQkiVw6aUwZQqcckrQVYlIColkyCUD2F7r8Y6a5xrMzPqZWbGZFZeXl/+Yt0g8zvnw7tgR3nzTLxBaskRhLiJxF0mg1zXw637MhznnJjnncpxzOa3CsLx9xw4/c6VvXzjvPH+a0G23aaxcRAIRSaDvAGoPAp8ElMWmnCThHEyb5rvy5cv9FrfLlkGbNkFXJiIpLJJAXw20NbM2ZtYY6Ankx7asBFZWBtdc4/dhycqCjRv9bJajNANURIJVbwo55yqBAUAhsAV40Tm32cyGm1k3ADP7hZntAG4AJprZ5lgWHQjnYPp06NABXn0VHn0UiorgtNOCrkxEBIhwpahzrgAoOOC5+2r9vBo/FBNO//iHHxufPx8uvNAf0nzGGUFXJSLyAxonOBznYOZM35W/8gqMHu3HzBXmIpKAFOiHsnOnPz2oVy9o29Yv3x88GNLS6v+7IiIBUKDXZfZs35UvWAAjR8KKFXDmmUFXJSJyWAr02nbtgp494cYbITMT1q6Fu++Go0OxKaWIhJwC/Ttz5/qufM4cePhhWLnSPxYRSRJqPT/9FAYOhOefh+xsWLrUb64lIpJkUrtDz8/3qz1ffBEeeABWrVKYi0jSSs0O/fPP4c47/VFwWVl+i9tzzgm6KhGRI5J6HXpBge/KZ8yAe++F1asV5iISCqkT6Hv2wC23wNVXQ4sWfnhl+HBo3DjoykREoiI1Ar2w0Hfl06bBsGH+NKHzzgu6KhGRqAr3GPoXX8Bdd/mj4M46y09F7Nw56KpERGIivB36d9MPp0zxi4PWrlWYi0iohS/Qv/oK+veHyy+HJk38sv2RI/3PIiIhFq5ALyryXfmTT8KgQX5DrQsuCLoqEZG4CE+gDxsGF1/s911ZvhzGjIH09KCrEhGJm/AE+mmnwR13wIYN0KVL0NWIiMRdeGa53Hpr0BWIiAQqPB26iEiKU6CLiISEAl1EJCQU6CIiIaFAFxEJCQW6iEhIKNBFREJCgS4iEhLmnAvmg83KgY8C+fDYagnsCrqIgOke6B6A7gHE5h6c4pxrVdcLgQV6WJlZsXMuJ+g6gqR7oHsAugcQ/3ugIRcRkZBQoIuIhIQCPfomBV1AAtA90D0A3QOI8z3QGLqISEioQxcRCQkFuohISCjQfwQzu8LMSsxsq5kNqeP1X5vZWjOrNLMeQdQYaxHcg0Fm9q6ZbTSzZWZ2ShB1xlIE9+A2M9tkZuvNbIWZtQ+izlir7z7Uuq6HmTkzC91Uxgh+F/qYWXnN78J6M+sbk0Kcc/rTgD9AGvB34FSgMbABaH/ANZlAFvAs0CPomgO6BxcDP635+f8Bs4KuO4B7cFytn7sBrwRddxD3oea6Y4HlwFtATtB1B/C70Af4S6xrUYfecJ2Brc65bc65fcBM4NraFzjnPnTObQSqgygwDiK5B685576pefgWcFKca4y1SO7BF7UeHgOEcQZCvfehxoPAKODbeBYXJ5Heg5hToDdcBrC91uMdNc+lkobeg1uBRTGtKP4iugdmdruZ/R0fZgPjVFs81XsfzCwbONk5tzCehcVRpP8erq8ZgnzJzE6ORSEK9IazOp4LY+d1OBHfAzPrDeQAeTGtKP4iugfOufHOudOAPwD3xLyq+DvsfTCzo4CxwOC4VRR/kfwuLAAynXNZwFJgWiwKUaA33A6g9v+7ngSUBVRLUCK6B2Z2GfBHoJtzbm+caouXhv4ezAS6x7SiYNR3H44FOgJFZvYhcD6QH7IvRuv9XXDOfVrr38Bk4LxYFKJAb7jVQFsza2NmjYGeQH7ANcVbvfeg5j+zJ+LDfGcANcZaJPegba2HVwMfxLG+eDnsfXDO7XHOtXTOZTrnMvHfp3RzzhUHU25MRPK70LrWw27AllgUcnQs3jTMnHOVZjYAKMR/uz3VObfZzIYDxc65fDP7BTAXOB64xswecM51CLDsqIrkHuCHWJoCs80M4GPnXLfAio6yCO/BgJr/StkPfA7cFFzFsRHhfQi1CO/BQDPrBlQCn+FnvUSdlv6LiISEhlxEREJCgS4iEhIKdBGRkFCgi4iEhAJdRCQkFOgiIiGhQBcRCYn/D7vR6tKC+493AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# direct solution to linear least squares\n",
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "data = array([\n",
    "[0.05, 0.12],\n",
    "[0.18, 0.22],\n",
    "[0.31, 0.35],\n",
    "[0.42, 0.38],\n",
    "[0.5, 0.49]])\n",
    "# split into inputs and outputs\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "# linear least squares\n",
    "b = inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "print(b)\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with this approach is the matrix inverse that is both computationally expensive\n",
    "and numerically unstable. An alternative approach is to use a matrix decomposition to avoid\n",
    "this operation. We will look at two examples in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve via QR Decomposition\n",
    "#### b = R^−1 · Q^T · y\n",
    "The approach still involves a matrix inversion, but in this case only on the simpler R matrix.\n",
    "The QR decomposition can be found using the qr() function in NumPy. The calculation of the\n",
    "coefficients in NumPy looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QR decomposition solution to linear least squares\n",
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import qr\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "data = array([\n",
    "[0.05, 0.12],\n",
    "[0.18, 0.22],\n",
    "[0.31, 0.35],\n",
    "[0.42, 0.38],\n",
    "[0.5, 0.49]])\n",
    "# split into inputs and outputs\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "# factorize\n",
    "Q, R = qr(X)\n",
    "b = inv(R).dot(Q.T).dot(y)\n",
    "print(b)\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve via SVD and Pseudoinverse\n",
    "\n",
    "The Singular-Value Decomposition, or SVD for short, is a matrix decomposition method like\n",
    "the QR decomposition.\n",
    "#### X = U · Σ · V^T\n",
    "____\n",
    "Unlike the QR decomposition, all matrices have a singular-value\n",
    "decomposition. As a basis for solving the system of linear equations for linear regression, SVD\n",
    "is more stable and the preferred approach. Once decomposed, the coefficients can be found by\n",
    "calculating the pseudoinverse of the input matrix X and multiplying that by the output vector\n",
    "y.\n",
    "#### b = X+ · y\n",
    "Where the pseudoinverse X+ is calculated as following:\n",
    "#### X^+ = U · D^+ · V^T\n",
    "Where X+ is the pseudoinverse of X and the + is a superscript, D+ is the pseudoinverse of\n",
    "the diagonal matrix Σ and V T is the transpose of V . NumPy provides the function pinv() to\n",
    "calculate the pseudoinverse directly. The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVD solution via pseudoinverse to linear least squares\n",
    "from numpy import array\n",
    "from numpy.linalg import pinv\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "data = array([\n",
    "[0.05, 0.12],\n",
    "[0.18, 0.22],\n",
    "[0.31, 0.35],\n",
    "[0.42, 0.38],\n",
    "[0.5, 0.49]])\n",
    "# split into inputs and outputs\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "\n",
    "# calculate coefficients\n",
    "b = pinv(X).dot(y)\n",
    "print(b)\n",
    "\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='red')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve via Convenience Function\n",
    "- The pseudoinverse via SVD approach to solving linear least squares is the de facto standard.\n",
    "- This is because it is stable and works with most datasets. NumPy provides a convenience\n",
    "\n",
    "function named lstsq() that solves the linear least squares function using the SVD approach.\n",
    "The function takes as input the X matrix and y vector and returns the b coefficients as well as\n",
    "residual errors, the rank of the provided X matrix and the singular values. The example below\n",
    "demonstrate the lstsq() function on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00233226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Careers\\Machine Learning\\Hands_ON\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# least squares via convenience function\n",
    "from numpy import array\n",
    "from numpy.linalg import lstsq\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "data = array([\n",
    "[0.05, 0.12],\n",
    "[0.18, 0.22],\n",
    "[0.31, 0.35],\n",
    "[0.42, 0.38],\n",
    "[0.5, 0.49]])\n",
    "# split into inputs and outputs\n",
    "X, y = data[:,0], data[:,1]\n",
    "X = X.reshape((len(X), 1))\n",
    "# calculate coefficients\n",
    "b, residuals, rank, s = lstsq(X, y)\n",
    "print(b)\n",
    "# predict using coefficients\n",
    "yhat = X.dot(b)\n",
    "# plot data and predictions\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.plot(X, yhat, color='yellow')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "________________\n",
    "\n",
    "### 1. Basics of Linear Algebra for Machine Learning\n",
    "#### Discover the Mathematical Language of Data in Python\n",
    "## Jason Brownlee\n",
    "- © Copyright 2018 Jason Brownlee. All Rights Reserved.\n",
    "#### Edition: v1.1\n",
    "\n",
    "### 2.\n",
    "### 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
